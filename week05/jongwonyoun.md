- [4.1 데이터 아키텍처](#41---------)
- [4.2 데이터 타입과 형태](#42-----------)
- [4.3 데이터 스토어](#43--------)
    * [4.3.1 관계형 데이터베이스](#431-----------)
    * [4.3.2 NoSQL 데이터베이스](#432-nosql-------)
    * [4.3.3 파일 시스템 스토리지](#433------------)
    * [4.3.4 데이터 스토어 정리](#434-----------)
- [4.4 데이터 관리](#44-------)
    * [4.4.1 중앙 데이터 관리](#441----------)
    * [4.4.2 분산 데이터 관리](#442----------)
    * [4.4.3 하이브리드 데이터 관리](#443-------------)
    * [4.4.4 데이터 관리 정리](#444----------)
- [4.5 데이터 조합 패턴](#45----------)
    * [4.5.1 데이터 서비스 패턴](#451-----------)
        + [어떻게 동작할까요](#---------)
        + [어떻게 사용할 수 있나요](#-------------)
        + [고려해야 할 사항들](#----------)
        + [관련 패턴들](#------)
    * [4.5.2 조합 데이터 서비스 패턴](#452--------------)
        + [어떻게 동작할까요](#----------1)
        + [어떻게 사용할 수 있나요](#--------------1)
        + [고려해야 할 사항들](#-----------1)
        + [관련 패턴들](#-------1)
    * [4.5.3 클라이언트-사이드 매시업 패턴](#453-----------------)
        + [어떻게 동작할까요](#----------2)
        + [어떻게 사용할 수 있나요](#--------------2)
        + [고려해야 할 사항들](#-----------2)
        + [관련 패턴들](#-------2)
    * [4.5.4 데이터 조합 패턴 정리](#454-------------)
- [4.6 데이터 확장 패턴](#46----------)
    * [4.6.1 데이터 샤딩 패턴](#461----------)
        + [어떻게 동작할까요](#----------3)
        + [어떻게 사용할 수 있나요](#--------------3)
        + [고려해야 할 사항들](#-----------3)
        + [관련 패턴들](#-------3)
    * [4.6.2 명령과 조회 책임 분리 패턴](#462----------------)
        + [어떻게 동작할까요](#----------4)
        + [어떻게 사용할 수 있나요](#--------------4)
        + [고려해야 할 사항들](#-----------4)
        + [관련 패턴들](#-------4)
    * [4.6.3 데이터 확장 패턴 정리](#463-------------)
- [4.7 성능 최적화 패턴](#47----------)
    * [4.7.1 구체화된 뷰 패턴](#471----------)
        + [어떻게 동작할까요](#----------5)
        + [어떻게 사용할 수 있나요](#--------------5)
        + [고려해야 할 사항들](#-----------5)
        + [관련 패턴들](#-------5)
    * [4.7.2 데이터 지역성 패턴](#472-----------)
        + [어떻게 동작할까요](#----------6)
        + [어떻게 사용할 수 있나요](#--------------6)
        + [고려해야 할 사항들](#-----------6)
        + [관련 패턴들](#-------6)
    * [4.7.3 캐싱 패턴](#473------)
        + [어떻게 동작할까요](#----------7)
        + [어떻게 사용할 수 있나요](#--------------7)
        + [고려해야 할 사항들](#-----------7)
        + [관련 패턴들](#-------7)
    * [4.7.4 정적 콘텐츠 호스팅](#474-----------)
        + [어떻게 동작할까요](#----------8)
        + [어떻게 사용할 수 있나요](#--------------8)
        + [고려해야 할 사항들](#-----------8)
        + [관련 패턴들](#-------8)
    * [4.7.5 성능 최적화 패턴 정리](#475-------------)
- [4.8 신뢰성 패턴](#48-------)
    * [4.8.1 트랜잭션 패턴](#481--------)
        + [어떻게 동작할까요](#----------9)
        + [어떻게 사용할 수 있나요](#--------------9)
        + [고려해야 할 사항들](#-----------9)
        + [관련 패턴들](#-------9)
    * [4.8.2 신뢰성 패턴 정리](#482----------)
- [4.9 보안: 볼트 키 패턴](#49------------)
    + [어떻게 동작할까요](#----------10)
    + [어떻게 사용할 수 있나요](#--------------10)
    + [고려해야 할 사항들](#-----------10)
    + [관련 패턴들](#-------10)
    * [4.9.1 볼트 키 패턴 정리](#491-----------)
- [4.10 데이터 관리 패턴 구현 기술](#410----------------)
    * [4.10.1 관계형 데이터베이스 관리 시스템](#4101------------------)
    * [4.10.2 아파치 카산드라](#4102---------)
    * [4.10.3 아파치 HBase](#4103-----hbase)
    * [4.10.4 몽고DB](#4104---db)
    * [4.10.5 레디스](#4105----)
    * [4.10.6 아마존 dynamoDB](#4106-----dynamodb)
    * [4.10.7 아파치 HDFS](#4107-----hdfs)
    * [4.10.8 아마존 S3](#4108-----s3)
    * [4.10.9 애저 코스모스DB](#4109--------db)
    * [4.10.10 구글 클라우드 스패너](#41010------------)
    * [4.10.11 구현 기술 정리](#41011---------)
- [4.11 테스팅](#411----)
- [4.12 보안](#412---)
- [4.13 관측 가능성 및 모니터링](#413--------------)
- [4.14 데브옵스](#414-----)
- [4.15 마치며](#415----)


## 4.1 데이터 아키텍처


![](files/Pasted%20image%2020250928160727.png)


- data source
    - 사용자 입력, 센서 측정값 등 데이터를 입력하는 곳
    - data ingestion system에 데이터를 입력하거나, 데이터 스토어로 직접 데이터를 입력할 수도 있음
    - data ingestion system은 데이터를 이벤트나 메시지 형태로 다른 애플리케이션이나 데이터 스토어로 전달함
    - 이를 통해 신뢰할 수 있는 비동기 데이터 처리 기법을 구현할 수 있음
- data store
    - 데이터 아키텍처의 핵심
    - 다양한 형태의 데이터를 저장, 경우에 따라 공간을 확장
    - 이를 기반으로 보고서를 만들거나, 데이터 관련 API를 제공
- real-time/stream-processing system
    - 이벤트를 그때그때 처리해서 유용한 결과를 만들거나 경고, 알림 등을 제공
- batch processing system
    - 배치로 데이터를 제공받아 이를 처리하고, 그 결과를 데이터 스토어에 저장
    - 이는 다시 보고서로 제공되거나 API로 외부에 제공
    - 파일 시스템과 같이 다른 데이터 스토어에서 데이터를 읽어서 처리하고, 이를 관계형 DB처럼 다른 데이터 스토어에 또 저장할 수도 있다


- 클라우드 네이티브 마이크로서비스는 크기 조절이 자유롭고, 탄력적이며 관리가 쉽다.
- 클라우드 네이티브 데이터들도 전통적인 데이터 처리 분야와 좀 다르다
- 가장 중요한 특징은 데이터 포맷이 서로 다르거나, 다양한 형태의 데이터 스토어가 존재
- 고정된 스키마를 가지지 않고, 가용성, 성능 등의 이유로 여러 곳에 중복해서 존재하는 게 좋다
- 또한 여러 클라우드 네이티브 서비스가 같은 데이터베이스를 사용하지 않고 대신 각 서비스 고유의 데이터 스토어를 가지도록 하고, 외부에서 데이터에 접근할 수 있도록 API 제공
- 이런 데이터 분리 덕분에 크기를 쉽게 확장 가능


## 4.2 데이터 타입과 형태
- 애플리케이션은 크게 3가지 주요 데이터 타입에 큰 영향을 받음
    - 입력 데이터
        - 사용자 또는 클라이언트가 주는 데이터
        - JSON, XML, gRPC, Thrift 등
    - 설정 데이터
        - 환경 등과 관련된 값을 변수 형태로 전달
        - 최근에 YAML 많이 씀
    - 상태 데이터
        - 애플리케이션 자체가 현재 메시지나 이벤트에 기반한 상태를 기록하고, 저장
        - 현재 상태를 저장하고, 시작 시에 읽어올 수 있다면 애플리케이션이 재시작해도 이전에 처리하던 작업을 끊김없이 계속 진행할 수 있다


- 애플리케이션이 오로지 입력, 설정 데이터에만 영향을 받으면 이를 Stateless Application이라고 한다.
- 이는 구현이 쉽고, 언제든지 재시작 가능해서 확장이 쉽다


- 반면에 상태도 필요로 하는 애플리케이션을 Stateful Application이라고 한다
- 이는 상대적으로 구현이 어렵다.
- 상태를 반드시 저장해야 하고, 관리해야 재시작해도 문제없이 실행을 재개할 수 있다.


- 데이터 형태는 크게 3가지
    - 정형 데이터
        - 미리 정의한 스키마에 잘 맞는 데이터
    - 반정형 데이터
        - 데이터가 일부 구조적 형태
        - 데이터가 참조를 위한 키, 이름을 가지고는 있지만 모든 데이터의 형태가 같다고 보장할 수는 없음
        - JSON, YAML 등
    - 비정형 데이터
        - 참조 등을 위한 의미 있는 필드가 전혀 없다
        - 이미지, 비디오, 저수준 텍스트 콘텐츠 등


## 4.3 데이터 스토어
- 데이터에 따라 적합한 데이터 스토어를 사용해야 한다
- 정형, 반정형, 비정형 데이터에 따라, 그리고 확장성과 가용성 요구사항에 따라 적절한 데이터 스토어를 선택


### 4.3.1 관계형 데이터베이스
- 미리 정의한 스키마에 따라 정형 데이터를 저장
- SQL을 사용
- 데이터를 쓰기 전에 스키마를 정의해야 하는 Schema on Write 정책을 따르기도 한다.


- 인덱스, 정규화를 통해 읽기 및 쓰기 최적화
- ACID 지원해 트랜잭션 보장


- 관계형 데이터베이스는 반정형 데이터에는 잘 맞지 않는다.
- 다만, 데이터를 관계형 데이터베이스, NoSQL에 분리해서 저장하면 가져오는 데 부담이 커지므로 비정형 혹은 반정형 데이터를 blob이나 TEXT 형태로 저장하기도 한다.


- 클라우드 네이티브 애플리케이션 데이터 저장에도 좋은 선택지
- 각 MS가 별도의 관계형 데이터베이스를 사용하면 확장성도 좋고, MS와 DB를 단일 단위로 묶어서 배포하기도 좋다.
- 단, 설계부터 확장성이 떨어지긴 한다.
- primary, secondary 구조만 지원하고 여러 노드 중 단 하나에만 쓰기가 가능


- 따라서 저장하는 레코드 수가 데이터베이스가 효과적으로 처리할 수 있는 수를 넘지 않을 때 사용하는 게 좋다
- 고객 주문, 로그, 알림 등 데이터 크기가 계속 증가할 것으로 예상되는 경우 관계형 데이터베이스를 데이터 확장 패턴을 통해 배포하거나 다른 데이터 스토어를 쓰는 게 좋다.


### 4.3.2 NoSQL 데이터베이스
- not Only SQL로 이해하는 게 좋다.
- schema on read 정책을 따른다
    - 데이터를 읽을 때 스키마를 정의
    - 데이터를 쓸 때는 스키마를 정의할 필요가 없다
- 따라서 확장성과 성능이 중요한 빅데이터 처리에 많이 쓴다


- 기본적으로 데이터를 분산 저장하므로, 여러 클라우드 네이티브 애플리케이션에 쓸 수 있다.
- 성능 최적화를 위해 NoSQL DB는 보통 데이터를 정규화하지 않고, 중복 필드를 가지기도 한다.
- 데이터를 정규화하면 데이터를 가져올 때 여러 테이블 조인 등이 필요한데 분산 저장이라는 NoSQL 특성 때문에 성능이 떨어진다


- 성능 및 확장성 문제로 인해 소수의 NoSQL DB만 트랜잭션을 지원


- 관계형 DB와 달리 NoSQL DB는 제각각 동작 방법이 다르다
- 일관성, 가용성 제공 방식에 따라 아래와 같이 분류 가능


- key-value store
    - 레코드를 키-값 쌍으로 저장
    - 데이터 캐싱에 많이 사용
    - redis, Memcached, Ehcache
- column store
    - 각 행에 여러 column 값 쌍을 저장할 때 사용
    - schema on read 대표적
    - 데이터를 쓸 때는 몇 개의 컬럼이든 자유롭게 기록하고, 읽을 때는 원하는 컬럼만 명시
    - Apache Cassandra, HBase 등


![](files/Pasted%20image%2020250928173018.png)


- document store
    - JSON, XML 등 반정형 데이터 저장
    - 경로 표현식으로 저장된 데이터 처리도 가능
    - JSON, XML 덕분에 front랑 통신하는 API 분야에 많이 사용
    - MongoDB, CouchDB, CouchBase 등이 많이 쓰임
- graph store
    - 데이터를 node로 저장하고, edge를 통해 데이터 노드 간 관계를 표현
    - 저장하는 데이터는 다차원 형태, 소셜 미디어의 관계나 거래 네트워크 구축하고, 거래 사기를 탐지하는 등에 활용
    - Neo4j를 가장 많이 사용


- object store, time-series 등은 특정 목적을 가지고 사용하는 데이터를 저장하고 질의할 때 많이 쓴다
- 몇몇은 여러 분류에 포함되는 이른바 멀티 모델 형태로 동작하기도 한다
- DynamoDB는 key-value store이면서 document store이기도 한다.
- CosmosDB 등도 key-value store이자 document, graph store


- 기본적으로 분산 동작하므로 CAP 이론 적용 가능
- 모두 만족할 수는 없기에 NoSQL마다 선택이 다름


| 구분           | 일관성 우선                                     | 가용성 우선                |
|----------------|------------------------------------------------|----------------------------|
| 키-값 스토어   | 레디스, Memcached                              | 다이나모DB, Voldemort      |
| 컬럼 스토어    | 구글 클라우드 빅테이블, 아파치 HBase           | 아파치 카산드라            |
| 도큐먼트 스토어 | 몽고DB, 테라스토어                            | 카우치DB, 심플DB           |
| 그래프 스토어  | 애저 코스모스 DB                               | Neo4j                      |


- 경우에 따라서 일관성, 가용성 모두 제공하기도 함
- 카산드라는 일관성 수준을 ONE, QUORUM, ALL 수준으로 지정해서 사용


### 4.3.3 파일 시스템 스토리지
- 비정형 데이터를 쓸 수 있는 가장 좋은 방법
- NoSQL과 달리 데이터에 대한 이해가 필요가 없고, 데이터 읽기 및 쓰기 성능 최적화에 초점을 둔다
- 대용량 데이터 캐시로 사용하기도 함


- 가장 저렴하지만 텍스트나 반정형 데이터 저장하기에는 좋지 않을 수 있음
- 단일 데이터 검색에도 여러 파일을 읽어야하는 경우가 있기 때문
- 이런 경우 Solr나 Elasticsearch 등의 검색 시스템을 쓰는 게 좋다.


- 저장하는 데이터가 점점 증가하는 경우 분산 파일 시스템을 사용
- HDFS, S3, Azure Storage Service, Google Cloud Storage 등


### 4.3.4 데이터 스토어 정리
- 데이터가 연관성이 강하고, 트랜잭션을 보장해야 한다면 관계형 데이터 스토어 사용
- 반정형, 비정형 필드를 가지고 있다면 NoSQL이나 파일 시스템에 저장해 트랜잭션 보장하면서 확장성을 제공
- 데이터가 아주 크고, 질의 기능을 제공해야 한다거나 데이터가 반정형이거나 그래프 처리 같은 특수 기능이 필요하다면 NoSQL
- 콘텐츠 처리가 필요없다면 파일 시스템 스토어


## 4.4 데이터 관리


### 4.4.1 중앙 데이터 관리
![](files/Pasted%20image%2020250928182740.png)
- centralized data management 방식은 전통적인 데이터 중심 애플리케이션에서 자주 사용
- 모든 데이터를 단일 DB에 저장하고, 여러 컴포넌트가 단일 DB에 접근


- 이는 테이블 정규화 가능, 아주 높은 데이터 일관성 제공
- 여러 컴포넌트가 모든 DB 테이블에 접근이 가능해 중앙 데이터 스토어가 여러 테이블에 데이터를 빠르게 저장하고 가져올 수 있음
- 그러나 DB와 애플리케이션 간 강한 연관성이 생기고, 애플리케이션을 독립적으로 개선하고 발전하기 어려워짐
- 이런 특성 때문에 클라우드 네이티브 애플리케이션에서 피해야 할 패턴으로 여겨진다


### 4.4.2 분산 데이터 관리
- 각각을 독립적인 MS로 설계, MS가 각각 별도의 데이터 스토어 사용
- 이런 decentralized data management 방식은 각 마이크로서비스가 다른 마이크로서비스에 영향을 미치지 않고 크기 조절을 자유롭게 할 수 있음
- 이러면 DB와 애플리케이션 간 강한 연관성이 생기지 않고, 쉽게 애플리케이션을 바꿀 수 있음


- 데이터를 관리하거나 바꿀 여지가 많지 않지만 개발 팀이나 소유자가 별도로 나뉘어있는 경우 MS 별로 데이터를 분리하면 데이터 관리나 소유권 문제를 쉽게 해결할 수 있음
- 새로운 기능 구현, 릴리스 소요 시간 등을 단축 가능


![](files/Pasted%20image%2020250928183006.png)


- 이 방식을 쓰면 서비스별로 데이터에 더 적합한 데이터 스토어 사용 가능


### 4.4.3 하이브리드 데이터 관리
![](files/Pasted%20image%2020250928183121.png)
- 단일 데이터베이스를 사용하면 위 내용 말고도 여러 운영상의 장점이 있음
- 보안 정책 강제, 데이터 보호 법률 적용 등
- 분산 데이터 관리 방식의 단점 중 하나는 별도 데이터 스토어를 쓰는 데서 오는 비용 부담
- 따라서 크지 않은 조직은 hybrid data management 방식을 사용하기도 함
- 같은 팀이 서비스를 관리하고, 같은 바운디드 컨텍스트 내에 존재
- 단, 다른 서비스가 사용하는 테이블에 접근하지 않도록 주의
- 나중에 DB 분리하기가 힘들어짐
### 4.4.4 데이터 관리 정리
![](files/Pasted%20image%2020250928183143.png)
- 독립적인 데이터 스토어를 구축하고, 잘 정의된 API로 서로 통신


## 4.5 데이터 조합 패턴
![](files/Pasted%20image%2020250928183216.png)
- MS는 데이터 스토어에 있는 데이터에 대한 소유권이 있음
  ![](files/Pasted%20image%2020250928183249.png)
- 서비스에 부하가 많이 생기면, 데이터 가져오는데 지연이 생기고, 캐시 등을 써서 지연 시간을 줄일 수 있음


![](files/Pasted%20image%2020250928183257.png)
- 더 복잡해지면 서비스들을 더 작은 마이크로서비스들로 나눈다
- 이 과정에서 여러 서비스가 같은 데이터를 공유하지 않도록 연관 데이터 역시 분리해서 새로운 서비스로 이동
- 데이터를 두 개의 데이터베이스로 나누는 것이 직관적이지 않을 수 있고, 경우에 따라서는 다른 방법을 사용해서 데이터를 안전하게, 재사용 가능한 방법으로 공유해야 할 수도 있다.


### 4.5.1 데이터 서비스 패턴
- data service pattern은 데이터를 서비스 형태로 제공하고, 이를 데이터 서비스라고 지칭
- 데이터 서비스가 데이터에 대한 소유권을 지님, 데이터 스토어에 데이터 추가하고 가져오는 책임을 가짐
- 간단한 조회를 하기도 하고, 응답을 위해 복잡한 작업을 하기도 함


#### 어떻게 동작할까요
- 서비스로 제공하면 더 많은 제어가 가능
- 다양한 조합으로 데이터 제공, 보안 적용, 정책 기반 자원 사용 제한 등
- 간단한 읽기 및 쓰기 작업, 여러 테이블 조인이나 stored procedure 실행 등
- 캐시로 읽기 성능 향상 등


![](files/Pasted%20image%2020250928184936.png)


#### 어떻게 사용할 수 있나요
- 여러 MS가 데이터 접근할 때
    - 한 서비스가 데이터에 대한 소유권을 가지고, 다른 MS에서는 데이터 쓰기만 하기
- 레거시 혹은 전용 데이터스토어를 다른 서버에서 쓸 수 있도록 추상화
    - 레거시 DB가 있고 이걸 C# 드라이버로 접근할 수 있다면 다른 애플리케이션도 다 C#이어야 함
    - API로 하면 내부 구조, 기술 등을 전혀 신경쓰지 않고 작업 가능
    - DB를 나중에 교체하는 것도 가능


#### 고려해야 할 사항들
- 여러 서비스가 같은 데이터 접근하는 건 피해야 함
- 강한 연관성이 생기고, 각 MS가 독자적으로 발전하기 어렵게 만든다
- API로 연동하면 연관성을 조금 느슨하게 만들 수 있다.


- 특정 MS가 데이터와 분명한 연관성을 지니면 이 패턴을 사용해서는 안 된다.
- 불필요한 MS가 생기고, 추가적인 관리 부담이 생김
#### 관련 패턴들
- 캐싱 패턴
    - 로컬 또는 분산 캐싱으로 읽기 성능 최적화
- 성능 최적화 패턴
    - 조인 연산, stored procedure 실행 등 복잡한 질의를 처리해 성능 향상
- 구체화된 뷰 패턴
    - 로컬 스토어에 중복 저장하고, materialized view 만들어서 성능 향상
- 볼트 키 패턴
    - API 보안 + audit


### 4.5.2 조합 데이터 서비스 패턴
- composite data services pattern
- 하나 이상의 데이터 서비스로부터 데이터 읽어서 조합하고, 필요한 경우 더 복잡한 작업을 통해 명료한 데이터 제공
- 사용자가 아닌 서비스 쪽에서 데이터를 조합해서 server-side mashup pattern이라고 한다.


#### 어떻게 동작할까요
![](files/Pasted%20image%2020250930205059.png)
- 서비스 오케스트레이션과 비슷
- 여러 서비스와 자신의 데이터 스토어에서 데이터를 가져와 조합한 데이터를 제공
- 직접 데이터 조합 안 해도 됨 + 캐시로 성능 향상


#### 어떻게 사용할 수 있나요
- 비슷한 조합을 여러 곳에서 사용하면 한 곳에서 대신 해주면 편함
- 또한 클라 영향 없이 데이터 조합 로직을 바꾸는 것도 가능
- 캐시로 성능 향상도 가능


#### 고려해야 할 사항들
- 여러 MS가 조합하는 데이터가 비슷할 때만 사용
- 아니면 불필요한 서비스 계층만 생기고, 서비스 재사용하는 경우도 줄어든다
- 클라 복잡도를 줄이고, 데이터를 재사용하고, 서비스 계층을 추가함으로써 생기는 추가 지연 시간과 관리 복잡도를 비교해서 이득이 클 때만 사용
    - 흠 내부 서비스 찔러서 오히려 지연 시간 면에서는 이득을 볼 수 있지 않나요?


#### 관련 패턴들
- 캐싱 패턴
    - 캐시로 성능 최적화
    - 경우에 따라서는 뒷단 서비스가 죽은 경우에도 데이터 제공 가능
- 클라이언트 사이드 매시업 패턴
    - 클라 쪽에서 데이터를 조합할 수도 있음
    - 비동기 읽기가 가능하고, 부분 데이터 만으로 데이터 조합이 가능하면 좋은 선택이 될 수도 있음


### 4.5.3 클라이언트-사이드 매시업 패턴
- client-side mashup pattern
- 클라에서 여러 데이터 서비스를 찔러 조합
- 클라는 보통 웹 브라우저, 비동기 호출로 데이터 가져옴


#### 어떻게 동작할까요
![](files/Pasted%20image%2020250930205051.png)


- 비동기 데이터 로딩 사용
- 일부분을 화면에 표시하면서 동시에 데이터를 불러와 나머지를 표시
- 그때그때 표시하는 게 사용자 경험 측면에서 좋다
- 이를 RIA(Rich Internet Application)이라고도 부른다


#### 어떻게 사용할 수 있나요
- 중요한 데이터를 낮은 지연시간으로 보여주기
    - 중요 정보를 빠르게 불러오고
    - 나머지 자세한 정보를 동적으로 업데이트
- 웹 페이지를 훨씬 더 빨리 불러오는 듯한 효과
    - 일부만 먼저 보여줘도 훨씬 빠르게 로딩된 것 같은 착각


#### 고려해야 할 사항들
- 부분 데이터를 바로 보여줄 수 있거나, 일부 데이터를 의미있게 사용할 수 있는 경우에만 사용
- 전체 데이터를 조합하거나, 일부 데이터를 다른 데이터와 합쳐야만 하는 경우에는 사용하지 않기


#### 관련 패턴들
- 조합 데이터 서비스 패턴
    - 콘텐츠를 동기적으로 가져와 데이터를 조합하는 것이 자주, 여러 서비스에서 쓰인다면 좋다
- 캐싱 패턴
    - 지연 속도 개선


### 4.5.4 데이터 조합 패턴 정리


|패턴|사용해야 할 경우|사용하면 안되는 경우|이점|
|---|---|---|---|
|**데이터 서비스**|• 단일 서비스가 데이터를 소유하지 않으며, 여러 마이크로서비스가 데이터에 의존하는 경우|• 데이터가 본질적으로 특정 서비스에 귀속되는 경우, 불필요한 마이크로서비스를 추가하게 되면 관리 복잡도만 증가함|• 서비스 간 결합도를 낮춤<br>• 공유 데이터에 대한 작업을 더 잘, 그리고 안전하게 처리할 수 있음|
|**조합 데이터 서비스**|• 많은 클라이언트가 필요한 데이터를 얻기 위해서 여러 서비스에 질의를 보내는 경우, 그리고 이런 데이터를 여러 클라이언트가 공통으로 사용하고 재사용이 가능한 경우|• 하나 또는 소수의 클라이언트에서만 사용하는 데이터의 경우<br>• 클라이언트에서 데이터를 조합하는 방법을 일반화하여 다른 클라이언트에서 재사용이 불가능한 경우|• 데이터를 얻기 위한 클라이언트 측의 중복 작업을 줄여주고 이를 공통 서비스로 제공<br>• 캐시나 정적 데이터 등을 통해 데이터를 더 탄력적으로 제공할 수 있음|
|**클라이언트 사이드 매시업**|• 일부 데이터 만으로도 의미 있는 작업이 가능한 경우, 예를 들어 웹 브라우저에서 다른 데이터에 종속적이지 않은 데이터만 별도로 표시하는 경우|• 별도로 가져온 데이터들을 합치거나 조합하는 등 별도의 처리과정을 거쳐야만 의미 있는 작업이 가능한 경우|• 좀 더 응답이 빠른 애플리케이션을 만들 수 있음<br>• 사용자 대기 시간을 줄일 수 있음|


## 4.6 데이터 확장 패턴
- 부하 증가하면 서비스나 데이터 스토어가 병목
- 빅데이터라면 NoSQL이나 분산 파일 시스템
- 이는 데이터 확장, 분할 등을 쉽게 할 수 있게 해줌


- 단, 데이터 일관성이나 트랜잭션 같은 요구사항이 있다면 관계형 데이터베이스 사용
- 이는 확장성이 고려되지 않음
- 따라서 이는 구조를 변경하여 확장성을 구현


### 4.6.1 데이터 샤딩 패턴
- 데이터를 샤드로 나누어서 데이터 저장 및 읽기 규모를 자유롭게 조절
- 데이터를 하나 또는 여러 속성에 따라서 분할


#### 어떻게 동작할까요
- 수평, 수직, 기능적 샤드


- 수평적 데이터 샤딩
  ![](files/Pasted%20image%2020250930205455.png)
- 각 샤드는 같은 스키마를 사용, 샤딩 키에 따라 서로 다른 데이터 레코드를 지님
- 데이터베이스 테이블은 각 샤딩 키에 따라서 여러 노드에 나뉨
- 주문 ID에 따라 세 개의 샤드로 나뉨



- 수직적 데이터 샤딩
  ![](files/Pasted%20image%2020250930205813.png)
- 같은 스키마를 사용하지 않고, 서로 다른 데이터 필드를 가질 수 있음
- 각 샤드는 다른 샤드에 있을 필요가 없는 테이블 데이터 일부를 가진다
- 데이터 접근 빈도에 따라서 데이터를 나눌 때 좋다.


- 기능적 데이터 샤딩
  ![](files/Pasted%20image%2020250930205849.png)
- 사용 목적이나 기능에 따라 나눌 수도 있다.


- 수직적, 기능적 데이터 샤딩은 기능 분리에 한계가 있다.
- 결국 데이터 더 확장하기 위해서는 수평적 데이터 샤딩을 사용할 수밖에 없는 시점이 온다.
- 수평적 데이터 샤딩을 할 때는 다음 방법으로 어디에 데이터를 저장할지 결정한다.


- 디렉토리 기반 샤딩
    - 검색 서비스, 분산 캐시를 통해서 샤드 키와 실제 데이터의 위치 간 정보를 저장
    - 데이터를 가져올 때 샤드 키로 위치를 찾고, 거기서 데이터를 가져옴
    - 데이터가 재배치되는 경우 클라는 변경된 위치를 찾기 위해 다시 샤드 키로 정확한 위치를 검색해야 함
- 범위 기반 데이터 샤딩
    - 샤딩 키가 연속적이라면 쓰기 좋음
    - 범위로 나누어서 샤딩
    - 날짜나 시간에 따라 데이터를 나누고 저장할 때 좋음
- 해시 기반 데이터 샤딩
    - 데이터 필드를 샤드 키로 쓰거나, 날짜 범위로 데이터를 나누면 균등하지는 않음
    - 조금 더 균등한 걸 원한다면 해시 데이터 기반 샤딩을 할 수 있음
    - 샤드 키로 해시 값을 만들고, 이걸로 위치를 결정
    - 데이터의 범위 단위로 질의하는 경우 잘 맞지 않지만 개별 데이터 질의에는 좋다
    - 검색 서비스와 함께 써서 해시 값과 그에 대한 샤드 위치를 저장하는 방법을 쓰기도 함


- 샤딩을 제대로 쓰려면 고유 데이터를 식별할 수 있는 하나 이상의 데이터 필드가 있거나, 데이터를 의미있는 하위 그룹으로 나눌 수 있는 데이터 필드가 필요
- 샤드 키와 관련된 데이터 필드 값은 고정되어 데이터가 변해도 해당 값은 절대 변하지 않아야 한다
- 데이터 필드 값이 바뀌면 샤드 키가 바뀌어서 데이터를 재배치해야한다.
    - 피하는 게 좋다


#### 어떻게 사용할 수 있나요
- 데이터를 싱글 노드에 저장하지 않거나, 데이터를 분산해 지연 시간을 낮출 때


- 싱글 노드에서 멀티 노드로 확장
    - 스토리지, 연산, 네트워크 대역폭 등이 병목일 때 데이터 샤딩을 사용
    - 수평 확장이 가능해짐
- 데이터 조회 시간 단축을 위한 데이터 분리
    - 여러 필드를 조합해 샤드 키를 만들고, 데이터를 분리
    - A, B로 샤드 키를 만들면 두 값으로 위치를 찾아서 빠르게 조회 가능
    - 만약 A, C만 알면 샤드를 찾을 수 없음 -> 계층적 샤드 키를 사용
    - A에 해당하는 샤드를 모두 찾고, 거기서 C로 검색 -> 검색하는 샤드 수를 줄일 수 있음
    - 혹은 A, C로 부 샤드키를 만들고 색인을 관리하기도
    - 단, 데이터를 변경할 때 부 샤드키도 변경해야 하므로 데이터 수정 비용이 커짐
    - 혹은 날짜나 시간 범위로 데이터를 나눌 수 있음.
    - 최근 데이터를 핫 샤드에 저장하고, 나머지 주문들을 아카이브 샤드에 저장
        - 대신 주기적으로 데이터 이동이 필요함
- 지리적 데이터 분산
    - 클라가 지역 별로 분산된 경우 지역에 따라 데이터를 나누고, 가까운 데이터를 지역별로 모을 수 있다
    - 이렇게 하면 요청에 대한 응답 시간이 빨라짐
    - 단, 전 세계를 대상으로 데이터를 조합해야 한다면 모든 샤드를 조회해야 함
        - 이 경우 가장 빠르게 응답한 첫 데이터 먼저 보내주고 이후 나머지 데이터를 조합한다거나 등
        - 혹은 전체 데이터를 잘 캐싱하거나


#### 고려해야 할 사항들
- 샤드 데이터 양을 최대한 비슷하게 만들어서 부하가 고르게 분산되도록
- 부하가 균등하지 않으면 데이터 재배치 필요
- 데이터 변경으로 샤드 불균형은 언제든지 발생할 수 있음


- 이런 재배치 작업을 효율적으로 하려면 샤드 크기를 가급적 작게 유지
- 장기적으로 뛰어난 확장성, 전체 시스템 영향 적게 데이터 재배치 빠르게 가능


- 장애 상황 대비 여러 개의 샤드 복사본 유지하면 좋다
- 가용성도 높아지고, 전체 시스템 중단 없이 유지보수 작업 가능해짐


- 여러 샤드 간 데이터 aggregation 처리는 종류별로 다르다
- 평균, 최소, 최대 등은 각 샤드에서 처리한 데이터를 합쳐서 계산 가능
- 그러나 중앙값 등은 모든 데이터가 필요해 샤딩으로 구현이 어렵다.


- 샤드 키를 만들 때 자동 증가 필드는 쓰지 않는 게 좋다.
- 각 샤드가 서로 통신하지 않으므로 중복이 발생할 수 있음
    - 데이터 재분배시 귀찮아짐


- 샤드 키는 최대한 균등 배분 가능한 값을 선택


#### 관련 패턴들
- 구체화 된 뷰 패턴
    - 각 샤드의 종속 데이터를 서비스의 로컬 스토어에 복제해 성능 향상, 데이터 스토어 호출 횟수 줄이기
    - 단, 약한 일관성을 지니므로 일관성이 그렇게 중요하지 않을 때 사용
- 데이터 지역성 패턴
    - 서로 연관이 있는 데이터들을 샤드에 모아 색인을 만들고, 더 효과적인 조회를 위해 stored procedure 실행


### 4.6.2 명령과 조회 책임 분리 패턴
- CQRS는 변경과 질의를 분리하고, 각각의 동작이 서로 다른 데이터 스토어를 다루도록 해 데이터 변경과 조회를 더 빠르게 처리
- 데이터를 더 다양하게 다룰 수 있게 해주고, 높은 확장성과 보안성
- 변경 및 질의 모델을 독립적으로 변경 가능, 각 모델에 영향을 거의 미치지 않음


#### 어떻게 동작할까요
![](files/Pasted%20image%2020250930211050.png)
- 변경과 조회를 별도의 서비스로 나눔
- 각 서비스가 변경과 읽기를 서로 다른 노드에서 수행
- 덕분에 쉽게 모델링하고 서비스들이 독립적으로 크기 확장 가능


- 명령과 질의에서는 데이터 스토어에 특화된 정보를 제공하면 안 된다. 애플리케이션과 관련된 데이터를 다루어야 한다.
- 서비스에 명령을 전달하면 메시지를 해석해서 데이터 스토어를 변경
- 이는 비동기로 질의 서비스로 전달되어 데이터를 저장
    - 카프카와 같은 로그 기반 큐 시스템. 이벤트 소싱 패턴
- 질의 서비스는 이벤트 큐에서 데이터를 읽고, 데이터 질의에 최적화된 패턴으로 로컬 스토어에 데이터를 변경
#### 어떻게 사용할 수 있나요
- 명령, 질의 영역에서 서로 다른 도메인 모델 쓰고 싶을 때
- 성능, 보안 문제로 데이터 변경과 읽기를 분리하고 싶을 때


- 명령, 질의 영역에서 서로 다른 도메인 모델 쓰고 싶을 때
    - 온라인 쇼핑몰
    - 재고 관리는 관계형 데이터베이스
    - 그러나 매번 상품 조회할 때는 여러 데이터를 묶어서 JSON 변환하면 시간이 많이 소요됨
    - 이 경우 CQRS로 JSON 형태로 도큐먼트 스토어에 저장해두면 좋음
    - 명령과 질의 모델이 강하게 결합되지 않으므로 서로 다른 팀에서 개발 가능
        - 독자적으로 각 모델을 발전


- 작업 분산과 데이터 경합 감소
    - 보안 검증, 메시지 변환 등 높은 성능을 요구하는 데이터 쓰기 작업, 복잡한 조인 연산이나 데이터 매핑과 같은 질의 작업을 처리하는 경우 CQRS를 쓸 수 있음
    - 명령과 질의를 분리해 서로가 미치는 성능 영향도 줄이고, 시스템 확장성도 올릴 수 있다.
    - 질의만 더 확장하고, 변경은 줄이는 등 서로 다른 확장성 요구사항도 처리 가능


#### 고려해야 할 사항들
- 명령, 질의 분리해 높은 가용성 제공
- 질의는 거의 무한한 확장 가능
- 단, 명령은 데이터 샤딩 등을 사용해야 할 수 있고, 이때 데이터를 나누고 합치는 과정에서 발생할 수 있는 잠재적인 데이터 충돌을 방지해야 한다.


- CQRS는 높은 일관성이 필요한 경우 쓰면 안된다.
- 데이터는 비동기로 동기화된다.
- 동기 복제를 하면 데이터 스토어 잠금을 얻기 위해 서로 경합하고, 그 결과 지연 시간이 증가한다.


- 명령과 질의를 분리하기 위해 ORM을 쓸 수 없다.
- 이런 도구는 DB로 조합 모델을 만드므로 CQRS를 할 때는 생성된 모델을 직접 수정하거나 처음부터 만들어야 한다.


- CQRS는 대단해보이지만 이를 적용하면 시스템 구조가 매우 복잡해진다.
- 이벤트 소싱 패턴으로 데이터 소스 변경을 관리해야 하고, 중복 및 실패 이벤트 처리가 필요하다.
- 따라서 명령 및 질의가 간단하고, 비즈니스 로직이 복잡하지 않다면 CQRS는 쓰지 않는 게 좋다.
- 오히려 관리의 복잡도 증가로 인한 단점이 더 크다.


#### 관련 패턴들
- 이벤트 소싱 패턴
    - 명령 서비스에서 갱신 이벤트를 질의 서비스로 이벤트 소싱으로 전달
    - 약한 일관성을 제공, 시스템 구조를 더 복잡하게 만든다
- 구체화된 뷰 패턴
    - 명령과 질의 모델이 간단하면 CQRS 대신 구체화된 뷰 패턴 사용해서 확장성 높이는 게 좋다
- 데이터 샤딩 패턴
    - 데이터를 분리하고 명령 서비스를 확장
    - 질의 서비스는 복제가 쉬워서 이점이 크지 않다
- API 보안


### 4.6.3 데이터 확장 패턴 정리


|패턴|사용하면 좋은 경우|사용해서는 안 되는 경우|이점|
|---|---|---|---|
|**데이터 샤딩**|• 데이터에 각 데이터를 고유하게 식별할 수 있는 하나 또는 그 이상의 필드가 있어서 데이터를 하위 집합으로 묶을 수 있는 경우|• 샤드 키를 통해 각 샤드에 균등한 크기의 데이터를 저장할 수 없는 경우<br>• 전체 데이터 셋의 중앙 값 실행과 같이 데이터 처리 작업에 전체 데이터가 필요한 경우|• 각 데이터의 필드를 조합해서 샤드 키를 만들고 데이터를 샤드 단위로 묶을 수 있음<br>• 클라이언트와 지역적으로 가까운 곳에 관련 데이터를 저장하고 최적화할 수 있음<br>• 계층적 샤드 또는 시계열 기반 샤드를 만들어서 검색 시간을 최적화할 수 있음<br>• 샤드 키가 없는 질의를 별 생각없이 사용해서 처리할 수 있음|
|**명령 및 조회 책임 분리(CQRS)**|• 애플리케이션에서 다음과 같이 고성능을 요구하는 데이터 변경 작업을 처리하는 경우:<br>- 데이터 검증<br>- 보안성 검증<br>- 메시지 변환<br>• 복잡한 조인 연산 또는 데이터 매핑과 같이 고성능 질의 연산을 처리해야 하는 경우|• 명령(데이터 변경)과 조회(데이터 질의) 서비스 간 높은 일관성이 요구되는 경우<br>• 명령과 질의 모델 간 연관성이 큰 경우|• 명령 및 질의 작업 간 영향도를 최소화 함<br>• 명령 및 질의 데이터를 각각의 경우에 잘 맞는 별도의 데이터 스토어에 저장하고 사용할 수 있음<br>• 명령 및 질의 간에 별도의 보안 정책을 적용할 수 있음<br>• 명령 및 질의 서비스를 서로 다른 팀에서 개발하고 관리할 수 있음<br>• 고가용성을 제공함|


## 4.7 성능 최적화 패턴
- 데이터는 병목 현상의 주요 원인 중 하나
- 확장하기 어렵고 일관성 등의 요구사항으로 경합이 벌어지며, 분산된 데이터 동기화에 대한 부하가 발생


- 성능을 올리는 기본적인 방법 중 하나는 색인 만들기
    - 검색 성능을 올릴 수 있지만 과도한 색인은 오히려 읽기와 쓰기 성능 모두 저하
    - 쓰기는 여러 개의 색인을 변경해야 해서 쓰기가 증가하고
    - 읽기는 모든 색인을 메모리에 가지고 있을 수 없기에 여러 번의 읽기 작업이 오히려 수반될 수도 있다.


- 읽기 모델을 간단하게 만드는 데는 데이터 비정규화가 좋다
- 조인 연산을 제거해 읽기 성능을 비약적으로 향상
- 쓰기 작업에는 정규화된 데이터 스토어를, 읽기 작업에는 비정규화된 데이터 스토어를 쓰면 좋다.


- 혹은 데이터를 처리하는 곳 가까이 두거나, 처리 코드를 데이터와 가까운 곳에서 실행하거나, 전송하는 데이터 양을 줄이거나, 미리 데이터를 전처리하거나 등 여러 방법이 있다.


### 4.7.1 구체화된 뷰 패턴
- materialized view pattern은 데이터를 처리하는 곳 가까운 곳에 미리 구체화된 뷰로 저장해 질의에 대한 데이터 조회를 효과적으로 처리
- 모든 데이터를 로컬 데이터 스토어에 저장, 데이터 포맷을 질의로 처리하는 데 최적화된 형태로 바꾼다.
- 이를 통해 더 이상 필요한 데이터를 가져오기 위한 서비스를 그때그때 호출할 필요가 없다.


#### 어떻게 동작할까요
![](files/Pasted%20image%2020251001211633.png)
- 의존 서비스에서 데이터를 가져와서 로컬 데이터 스토어에 저장하고, 구체화된 뷰를 만든다
- 조합 데이터 서비스 패턴처럼 질의를 효과적으로 처리할 수 있는 최적화된 뷰를 만들기도 한다.


- 이 패턴에서는 의존 서비스로부터 데이터를 비동기로 복제해서 사용
- 사용하는 DB가 비동기 복제를 지원하면 이걸 써서 가져오기도 함
- 없으면 이벤트 소싱 패턴으로 데이터를 복제


#### 어떻게 사용할 수 있나요
- 복잡한 조인 연산을 제거하고, 관련 서비스에 대한 결합도를 낮추어서 읽기 관련 작업을 효과적으로 처리


- 데이터 읽기 효율성 증대
    - 데이터 일부를 로컬에서 처리할 수 있고 나머지는 지연시간이 긴 외부 데이터 소스에서 가져와도 관계없을 때 사용
    - 리뷰 전체를 가져오지 말고 최고 리뷰, 최악 리뷰를 미리 복사해서 상품 세부 정보를 미리 제공하는 등
    - 같은 DB여도 조인은 오래 걸릴 수 있다.
    - 미리 질의 처리에 알맞는 데이터를 구체화된 뷰로 변환해두면 데이터를 더 효율적으로 처리하고 제공할 수 있다.
- 안전한 시스템에서 민감하지 않은 데이터 제공
    - 민감하지 않은 데이터만 미리 복제해주면 보안 및 검증 없이 빠르게 제공할 수 있다.


#### 고려해야 할 사항들
- 의존하는 데이터가 다른 유형의 데이터 스토어에 있거나, 불필요한 데이터가 많이 있는 경우 하위 데이터만 복제하고, 적절한 포맷으로 변경해서 저장해야 한다.
- 데이터를 로컬에서 처리함으로써 전반적으로 질의 성능을 올리고, 전송하는 데이터 양을 줄여서 대역폭 소모를 줄일 수 있다.
- 데이터 잠금 경합이 발생하지 않도록 비동기 복제를 사용한다.


- 읽기 성능 올려주고, 불필요한 데이터 처리할 필요 없고, 의존하는 서비스 파악할 필요 없어서 서비스 로직이 간단해짐


- 서비스 탄력성을 제공함
- 데이터가 로컬 스토어에 복제되어 원천 데이터 제공하는 곳에 문제가 생겨도 문제가 없음


- 그러나 데이터를 의존 서비스로부터 아주 빠르게 가져올 수 있거나, 의존하는 서비스가 빠르게 바뀌는 경우, 일관성이 매우 중요한 경우 쓰면 안 된다.
- 저장한 데이터가 무용해지고, 오히려 데이터 불일치를 초래


- 데이터 양이 아주 크거나, 원천 데이터가 자주 바뀌면 역시 이 패턴을 쓰면 안 된다
- 복제 지연이 발생할 수 있고, 대역폭 소모도 많아 전반적인 성능 및 정확도에 영향을 미친다.
- 이 경우 데이터 지역성 패턴을 쓰는 게 좋다.


#### 관련 패턴들
- 데이터 지역성 패턴
    - 코드 실행을 데이터와 가까운 곳에서 해서 데이터 조회를 더 효율적으로
- 조합 데이터 서비스 패턴
    - 데이터 조합을 서비스 수준에서 할 수 있거나, 의존 서비스가 정적 데이터를 가지고 있어서 캐싱할 수 있는 경우 구체화된 뷰 패턴 대신 사용 가능
- 명령 및 질의 책임 분리 패턴
    - 구체화된 뷰 패턴에서 질의 처리를 위해서 CQRS 사용 가능
- 이벤트 소싱 패턴
    - 데이터를 다른 곳으로 복제할 때 사용


### 4.7.2 데이터 지역성 패턴
- data locality pattern
    - 데이터 처리 로직을 최대한 데이터와 가까운 곳에서 실행하는 것
    - 서비스를 데이터와 같은 위치에 배포하거나, 데이터 스토어에서 로직을 실행하는 것
    - 실행 코드가 거의 제한 없이 데이터에 접근할 수 있어 빠른 실행이 가능하고, 결과 데이터를 보낼 때 소비하는 대역폭을 줄일 수 있다.


#### 어떻게 동작할까요
![](files/Pasted%20image%2020251001212157.png)
- 데이터를 옮기는 것보다 실행 코드를 옮기는 게 성능을 더 향상할 수 있다.
- CPU 자원이 충분하면 데이터 노드에서 질의를 처리해서 네트워크 전송 없이 대부분 데이터를 로컬에서 처리


- 이게 불가능하다면 같은 리전이나 데이터 센터에 배치해서 대역폭 소비를 최소화


![](files/Pasted%20image%2020251001213714.png)


- 혹은 stored procedure로 만들어서 실행


#### 어떻게 사용할 수 있나요
- 데이터 읽기 지연 시간 감소
    - 하나 이상의 데이터 스토어로부터 데이터를 읽어와서 정렬, 조인할 때 쓰면 좋다
    - 데이터 스토어에서 서비스를 실행하거나, 가장 많은 데이터를 전송해야 하는 데이터 스토어에서 서비스를 실행하면 네트워크 전송 양을 줄일 수 있다.
    - 또는 조합 서비스 패턴에서 서비스가 데이터 스토어와 다른 서비스 데이터를 조인하는 경우, 조합 서비스를 데이터 스토어 노드나 가까운 노드에서 실행하면 전반적인 성능을 향상할 수 있다.
- 데이터 조회 시 네트워크 대역폭 소비 감소
    - 데이터 집계나 필터링을 위해 여러 데이터 소스를 봐야하는 경우 유용하다
    - 이런 질의 결과는 일반적으로 입력 데이터에 비해 매우 작기 때문
    - 네트워크 대역폭 소비를 최적화할 수 있음
    - 혹은 데이터 스토어가 아주 크고 클라이언트가 지리적으로 분산된 경우 쓰기 좋다
    - 전반적으로 네트워크 대역폭에서 병목 현상을 겪는 경우 적용하기에도 좋다



#### 고려해야 할 사항들
- 데이터 노드의 CPU 자원 사용을 최대화할 수 있다
- 대부분 데이터 노드는 I/O 작업에 치중 -> CPU가 노는 경우가 많다
- 그렇다고 모든 실행 코드를 데이터 노드에서 실행할 수는 없다. 지나치게 많은 부하가 갈 수 있음


- 입력과 결과 데이터 크기가 큰 차이가 없는 경우 안 쓰는 게 좋다
- 성능 향상이나 대역폭 소비 절감 효과는 하나도 없이 노드 부하만 가중시킨다
- 네트워크 대역폭 소비 감소와 CPU 사용률 최대화 간 이점을 잘 조율해야 한다
- 데이터 노드에서 코드를 실행해서 발생할 수 있는 문제점보다 데이터 크기를 줄임으로써 얻을 수 있는 이점이 클 때 사용


- 데이터 스토어가 질의 마이크로서비스에서 전용으로 사용하는 경우에만 실행 코드를 데이터 스토어로 옮겨야 함
- 공유 데이터베이스에서 stored procedure를 실행하면 성능 및 관리 문제를 일으킬 수 있으므로 피해야 함
- 운영하다가 실수로 데이터 스토어 장애가 발생할 수도 있음
- 성능 이점이 없다면 서비스에서 직접 코드를 실행하는 게 더 좋다


#### 관련 패턴들
- 구체화된 뷰 패턴
    - 실행 코드 가까운 곳에 데이터 배치
    - 데이터 크기가 작거나 읽기 과정에서 복잡한 조인, 데이터 변환 등으로 CPU 많이 소모하는 경우
- 캐싱 패턴
    - 전처리한 데이터를 저장하고, 반복된 질의에 해당 데이터를 제공해 성능 향상


### 4.7.3 캐싱 패턴
- 이전에 처리한, 조회한 데이터를 메모리에 저장하고 향후 유사한 질의에 대하여 저장한 데이터를 사용하는 방식
- 서비스에서 반복하는 데이터 처리를 줄여주고, 이미 저장된 데이터와 연관된 의존 서비스를 호출하지 않아도 됨
#### 어떻게 동작할까요
- 캐시는 일반적으로 메모리에 데이터를 저장하는 데이터 스토어 형태로, 이전 데이터를 미리 저장해두고 이를 재사용
- 있으면 캐시 히트, 없으면 캐시 미스


- 캐시 미스가 발생하면 시스템은 데이터를 처리하거나 가져오고, 다시 캐시에 저장
- 이를 read-through cache operation이라고 한다.


- 데이터 변경 요청을 처리하는 경우 데이터 스토어에 이를 반영하고, 캐시에 저장된 데이터를 삭제하는데 이를 write-through cache operation이라고 한다.
- 캐시 데이터가 틀린 경우 cache invalidation이 반드시 필요하다.
- 이렇게 데이터를 읽고 변경하는 방식을 cache aside 방식이라고 한다.
- 대부분의 상업용 캐시가 이를 지원


- 캐시는 클라, 서버 둘 다 존재 가능
- 로컬 캐시를 쓰거나 공유 캐시를 쓰거나


- 메모리를 다 쓴 경우 이전 데이터를 지워야 함.
- 가장 자주 사용하는 정책은 LRU(Least Recently Used)
- 가장 오랫동안 사용되지 않은 데이터를 삭제하고, 그 자리에 새로운 데이터를 저장
- 가장 예전에 저장한 데이터를 지우는 FIFO, 가장 최근에 사용한 데이터를 지우는 MRU 등
- 혹은 발생한 이벤트 값에 따라서 데이터를 지우는 등
- 애플리케이션 성격에 맞게 고려


- 데이터를 캐시에 저장했는데, 다른 곳에서 원본 데이터를 변경할 수도 있다
- 캐시에 어떤 데이터를 오랫동안 가지고 있으면 캐시와 실제 데이터 사이의 불일치가 생길 수 있다
- 이는 캐시 데이터별로 유효 시간을 정함으로써 해결 가능


#### 어떻게 사용할 수 있나요
- 데이터 조회 시간 단축
    - 데이터 스토어보다 캐시가 더 빠른 경우 캐시를 쓸 수 있다.
    - 특히 데이터 스토어에서 데이터를 가져오는데 연산이 복잡하거나, 원격지에 있어서 네트워크 지연 시간이 높은 경우 사용 가능
- 정적 콘텐츠를 가져오는 시간 단축
    - 정적 데이터 혹은 거의 변경되지 않는 데이터 제공할 때 좋다
    - 메모리에 저장할 수 있는 정적 데이터는 해당 데이터 전체를 메모리에 저장하고, TTL 없이 제공해도 좋다.
    - 이를 통해 정적 데이터를 가져오는 시간을 획기적으로 개선할 수 있고, 원천 데이터 스토어에서 데이터를 읽어올 필요를 없게 만든다.
- 데이터 스토어 경합 감소
    - 데이터 스토어에 읽기 요청을 적게 보내서 데이터 스토어에서 발생할 수 있는 경합을 줄일 수 있다.
    - 데이터 불일치에 크게 영향받지 않는 경우 쓰기 작업을 많이 처리하는 스토어에 이 패턴을 적용해서 읽기 부하를 줄이고, 시스템 안정성을 올릴 수 있다.
    - 이 방법은 언젠가는 TTL이 지나거나 write-through cache 동작으로 데이터가 일치된다.
- 데이터 조회 시간 단축을 위해 데이터를 미리 가져오기
    - 주로 사용하는 질의 내용이 무엇인지 알고 있다면, 데이터 전체 혹은 일부를 미리 가져와서 캐시에 저장할 수 있다.
    - 보통 최근 일주일 내 주문 데이터를 요청한다면 서비스를 시작할 때 최근 일주일 분량의 데이터를 미리 가져와서 캐시에 저장할 수 있다.
    - 캐시가 없으면 초기 요청을 처리하는 과정에서 캐시 미스로 인해 서비스와 데이터 스토어에 많은 부하가 발생할 수도 있다.
    - 혹은 그 다음 질의에서 어떤 데이터가 필요한지 미리 예측해서 데이터를 미리 가져오는 것도 가능하다.
- 데이터 스토어 의존성 해소를 통한 고가용성 구현
    - 서비스 가용성이 데이터 일관성보다 더 중요한 경우, 캐싱을 통해 고가용성을 구현하는 것도 가능하다.
    - 백엔드 데이터 스토어가 제대로 동작하지 않는 경우에도 서비스는 캐시 데이터로 계속 동작할 수 있다.
    - 캐싱 패턴을 통해 로컬 캐시에 데이터가 없는 경우 공유 혹은 분산 캐시에서 데이터를 가져오고, 이마저도 없으면 데이터 스토어에서 데이터를 가져오는 구조
    - 이 패턴은 circuit breaker와 함께 사용해서 몇 차례 실패 후 백엔드 서비스나 데이터 스토어가 정상이 되었을 때 다시 연결을 복구하도록 만들 수도 있다.
    - 공유 캐시를 사용하는 경우 부 캐시 인스턴스를 항시 대기 상태로 두고, 데이터를 복제해두면 주 캐시 인스턴스가 동작하지 않는 경우 부 캐시를 쓰도록 해 가용성을 높이는 것도 가능하다.
      ![](files/Pasted%20image%2020251002195429.png)
- 단일 노드에서 저장할 수 없는 데이터를 캐시에 저장하기
    - 로컬 캐시나 공유 캐시가 필요한 모든 데이터를 저장할 수 없는 경우 분산 캐싱 시스템을 쓸 수도 있다
    - 데이터를 나누고 복제함으로써 확장성과 탄력성을 제공
    - read through, write through 동작을 지원하고, 데이터 스토어로부터 바로 데이터를 가져오고 변경하는 것도 가능
    - 분산 캐싱 시스템은 필요한만큼 캐시 서버를 추가해 확장성을 간단하게 구현할 수 있다.
    - 물론 분산 캐시는 로컬 캐시만큼 빠르지 않으며, 시스템 복잡도가 증가한다.
    - 분산 캐시를 구성하는 모든 노드는 같은 네트워크 내에 존재해야 하며, 서로 통신할 때 상대적으로 많은 대역폭을 사용할 수 있어야 한다. 아니면 데이터 동기화 문제가 발생한다.
    - 클라이언트가 지리적으로 분산된 경우 분산 캐시로 가까운 곳에서 빠르게 데이터를 저장하고 응답할 수도 있다.


#### 고려해야 할 사항들
- 캐시 데이터를 단일 데이터 소스로 사용해서는 안 되며, 고가용성을 반드시 만족할 필요도 없다
- 캐시를 사용할 수 없어도 애플리케이션은 제대로 동작해야 한다.
- 캐시는 메모리에 데이터를 저장하므로 언제든지 사라질 수 있고, 장기적으로 데이터를 영구 저장하는 것은 반드시 데이터 스토어야한다.


- 응답 데이터 대부분이 정적이고, 일부분이 동적이면 정적인 데이터만 캐시에 저장하는 것도 방법이다.


- 캐시를 삭제하는 정책 대신 데이터가 흘러 넘칠 때 로컬 캐시가 이를 대응하도록 만들 수도 있다.
- 넘치는 데이터를 디스크에 저장한다.
- 단, 데이터 관리가 복잡해지므로 이는 원천 데이터를 가져오는 것보다 디스크가 빠를 때만 써야 한다.


- 캐시 유효 시간은 너무 길거나 짧지 않게, 적당한 시간을 지정한다.
- 캐시 유효 시간이 너무 길면 데이터 스토어와 캐시 데이터 간 불일치가 많아지고, 너무 짧으면 캐시를 쓰는 의미가 없어진다.
- 일관성보다 조회 비용이 중요하면 일부러 TTL을 길게 잡을 수도 있다.


- 로컬 캐시의 가장 큰 문제는 서비스를 확장할 때 각자 로컬 캐시를 관리하므로 캐시 간 데이터 불일치가 발생할 수도 있다.
- 이런 문제는 메시징 시스템을 통해 pub-sub 패턴이나 이벤트 소싱 패턴으로 캐시 무효화를 시킬 수도 있다.


![](files/Pasted%20image%2020251002200249.png)


- 불필요한 캐시를 추가하면 메모리 소비가 증가하고, 성능이 떨어지며 데이터 불일치가 발생할 수 있다
- 캐시 도입 전에 충분한 부하 테스트를 통해 성능은 물론 캐시 히트, CPU, 메모리 사용량 등을 파악해야 한다.


- 가능하면 데이터 스토어처럼 캐시도 배치 업데이트를 하는 게 좋다
- 높은 부하가 걸리는 상황에서 대역폭 사용과 성능을 최적화할 수 있다.
- 여러 캐시 데이터가 동시에 변경되는 경우 낙관적 또는 비관적 방식을 사용할 수 있다.
- 낙관적 방식은 여러 캐시에서 동시에 데이터를 변경하는 경우가 없다고 가정하고, 캐시 업데이트하기 전에만 캐시에 동시에 쓴 경우가 있는지 검사
- 비관적 방식은 전체 업데이트 시간 동안 잠금을 걸어 동시에 다른 곳에서 데이터를 변경하지 못하도록 한다.
    - 이는 확장성이 떨어지므로 아주 짧은 시간이 소요되는 경우에만 써야한다.


- 또한 캐시를 강제 만료하거나 데이터를 다시 만들 수 있게 하는 게 좋다.
- 그러면 클라에서 서비스가 캐시를 강제 갱신하도록 할 수 있다.
- 캐시를 저장할 때 캐시 키에 임의의 값을 조합하는 방식으로 이를 구현할 수도 있다.
    - 클라가 캐시 키를 그대로 쓰거나, 새롭게 바꾸거나
- 이는 브라우저 캐시에 많이 사용
- 클라가 임의의 URI 값을 바꿈으로써 브라우저 캐시를 초기화


- 몇몇 상용 캐시 서비스는 볼트 키 패턴을 통해 데이터 보안성 제공
- 하지만 대부분은 보안을 염두하고 설계되지 않았으므로 캐시 데이터를 외부에 제공하는 것은 피한다.
- 대신, 데이터 서비스 패턴으로 서비스에 캐시를 구현하고 API로 이를 제공하는 게 좋다.


![](files/Pasted%20image%2020251002200626.png)


#### 관련 패턴들
- 데이터 샤딩 패턴
    - 데이터 스토어 확장처럼 캐시도 확장 가능
    - 지리적으로 데이터를 분산해서 데이터와 실 사용처를 가깝게 만들 수도 있다.
- 탄력적 연결성 패턴
    - 캐시 데이터를 사용할 수 없는 경우 데이터 원천을 통해 서비스
- 데이터 서비스 패턴
    - API 보안성과 데이터 서비스를 함께 사용해 분산 캐시에 대한 서비스 계층을 제공하고, 데이터 사용자에게 좀 더 비즈니스 친화적인 API 제공
- 볼트 키 패턴
    - 액세스 토큰을 통해 서드파티가 캐시에 안전하게 접근할 수 있게 해줌
    - 이는 캐싱 시스템이 이 기능을 지원할 때 써야함
- 이벤트 소싱 패턴
    - 모든 로컬 캐시에 캐시 무효화 요청을 전파할 때 쓸 수 있음
    - 캐시 데이터에 대한 약한 일관성 제공, 데이터 소스가 여러 서비스로 인해 변경되어 데이터가 쓸모없어지는 경우를 최소화해줌


### 4.7.4 정적 콘텐츠 호스팅
- static content hosting pattern은 데이터 스토어의 정적 콘텐츠를 클라이언트와 가까운 곳에 배포해서 낮은 지연 시간으로 클라이언트에게 콘텐츠를 제공
#### 어떻게 동작할까요
- 클라우드 네이티브 웹 서비스는 요청에 따라 동적으로 콘텐츠를 만들어서 제공
- 그러나 일부 클라는 HTML, css, js, image 등 많은 양의 정적 콘텐츠도 사용
- 이런 정적 콘텐츠를 사용할 때 MS를 쓰는 것보다 정적 콘텐츠 호스팅 패턴을 적용해서 CDN과 같은 정적 콘텐츠 스토리지에 보관하는 게 좋다.


![](files/Pasted%20image%2020251008174821.png)


- 동적 HTML 내에도 여러 정적 데이터에 대한 링크가 포함되어있다
- 브라우저는 이 링크로 정적 콘텐츠를 가져오는데, 이를 CDN으로부터 가져온다.


#### 어떻게 사용할 수 있나요
- 빠른 정적 콘텐츠 제공
    - 정적 콘텐츠는 거의 변하지 않기 때문에 정적 데이터를 지리적, 환경적으로 다른 여러 곳에 복제하고, 캐시에 저장해서 클라이언트에 가까운 곳에 콘텐츠를 배포
    - 이를 통해 클라이언트에게 빠르게 정적 데이터를 제공
- 렌더링 서비스의 자원 사용량 감소
    - 정적 데이터를 CDN이 제공하면 동적 콘텐츠만 MS가 제공하면 되므로 자원 사용량이 감소


#### 고려해야 할 사항들
- 클라에게 정적 콘텐츠를 제공하기 전에 수정해야 하는 경우에는 이 패턴 사용이 어렵다
- 또한 정적 콘텐츠의 크기가 작은 경우에도 잘 맞지 않는다
- 이 경우 직접 제공하는 게 훨씬 빠르다
- 정적 콘텐츠, 동적 콘텐츠 모두 사용하고 분명한 성능상 이점이 있을 때만 이 패턴을 사용


- 또한 이 패턴을 사용하면 클라 구현이 복잡해질 수도 있다
- 브라우저가 아니라 다른 클라에서 이 패턴을 사용하는 경우 이런 복잡한 작업을 클라가 직접 구현해야 한다.


- 어떤 경우에는 정적 콘텐츠를 안전하게 보관하고 싶을 때도 있다
- 인증된 사용자만 정적 콘텐츠에 접근하는 것을 허용하고 싶다면 API 보안과 데이터 서비스 패턴을 함께 사용하거나 볼트 키 패턴을 같이 사용하는 것을 권장


#### 관련 패턴들
- 데이터 샤딩 패턴
    - 정적 데이터가 많을 때는 이를 샤드 단위로 나눠서 관리
- 캐싱 패턴
    - 콘텐츠를 캐시에 저장해서 더 빠르게 제공
    - 정적 데이터는 거의 바뀌지 않으므로 캐시 데이터의 유효 기간을 지정할 필요가 없다
- 볼트 키 패턴
    - 정적 콘텐츠 시스템에 보안성을 제공
- 데이터 서비스 패턴
    - 정적 콘텐츠를 제공하는 서비스에 API 보안 기능 추가


### 4.7.5 성능 최적화 패턴 정리



|패턴|사용하면 좋은 경우|사용해서는 안 되는 경우|이점|
|---|---|---|---|
|**구체화된 뷰**|• 데이터 일부를 로컬에서 제공할 수 있으며 나머지 데이터는 지연 시간이 높은 외부 데이터 스토어에서 가져와서 처리할 수 있을 때<br>• 로컬 스토어로 옮기는 데이터 크기가 작으며 거의 변경되지 않을 때<br>• 보안 시스템을 통해서만 접근할 수 있지만 민감하지 않은 데이터를 제공해야 할 때|• 데이터를 외주 서비스에서 낮은 지연 속도로 가져올 수 있을 때<br>• 외주 서비스의 데이터가 빠르게 변경될 때<br>• 데이터의 일관성이 더 중요할 때|• 애플리케이션에 적합한 다양한 데이터베이스나 데이터를 저장할 수 있음|
|**데이터 지역성**|• 데이터를 여러 데이터 스토어에서 읽어서 조인이나 데이터 애그리게이션 연산을 수행할 때<br>• 데이터 스토어가 매우 크고 클라이언트가 지리적으로 분산되어 있을 때|• 질의의 결과가 입력 데이터 대부분을 포함할 때<br>• 데이터 노드에서 데이터를 처리하는 비용이 데이터를 네트워크로 전송하는 비용보다 클 때|• 데이터 조회 지연 시간을 낮추고 네트워크 대역폭 소모를 줄임<br>• CPU 사용 효율을 증대하고 전반적인 성능을 최적화함<br>• 결과 데이터를 캐시에 저장하고 요청을 더 효과적으로 처리함|
|**캐시**|• 정적 데이터 또는 거의 변경되지 않은 데이터 차원에 적합함<br>• 애플리케이션이 하나 이상의 클라이언트로부터 동일한 질의를 여러 번 받는 경우, 특히 다음 질의가 어떤 데이터를 요구할지 예측할 수 있는 경우<br>• 데이터 스토어 간 경합이 심하거나 여러 클라이언트로부터 동시에 데이터 조회 요청이 발생하는 것을 제대로 처리할 수 없을 때|• 데이터가 자주 변경되는 경우<br>• 신뢰할 수 있는 데이터 원본으로 사용해서는 안됨<br>• 데이터가 아주 중요하여 시스템이 데이터 불일치를 처리할 수 없는 경우|• 데이터 일부를 캐시에 저장해서 성능을 향상시킬 수 있음<br>• 캐시 배치 기법을 통해 중복 연산을 제거하고 성능을 향상시킴<br>• 캐시에 정적 데이터를 미리 읽어와서 제공할 수 있음<br>• 캐시 삭제 정책과 함께 사용하면 최근 또는 요구되는 데이터를 캐시에 저장할 수 있음|
|**정적 콘텐츠 호스팅**|• 클라이언트에서 요구하는 데이터 일부 또는 전체가 정적 콘텐츠인 경우<br>• 정적 데이터를 여러 환경 또는 지리적으로 떨어진 여러 위치에 제공해야 하는 경우|• 접근 시간이나 위치를 기반하는 것과 같이 클라이언트에 제공하기 전 정적 콘텐츠를 수정해야 하는 경우<br>• 제공하는 정적 콘텐츠의 크기가 작은 경우<br>• 클라이언트 측에서 정적 데이터와 동적 데이터를 받아서 조합할 수 없는 경우|• 지리적으로 데이터를 나누고 클라이언트와 가까운 곳에 저장함으로써 클라이언트에게 더 빠르게, 낮은 지연 시간으로 콘텐츠를 제공할 수 있음<br>• 렌더링 서비스의 자원 소모량을 줄일 수 있음|


## 4.8 신뢰성 패턴
- 데이터 손실은 일어나서는 안 된다.
- 무엇보다 신뢰성이 가장 중요함
- 데이터 수정이나 데이터 전송을 믿을 수 있는 방법으로 구현해야 함
### 4.8.1 트랜잭션 패턴
- transaction pattern은 여러 작업으로 이루어진 트랜잭션을 마치 하나의 작업 단위처럼 수행해서 일련의 작업들이 모두 완전히 끝나거나 전혀 이루어지지 않도록 만든다
- 데이터 무결성을 유지해주고, 서비스 실행에 문제가 없도록 해줌
#### 어떻게 동작할까요
- ACID
- 트랜잭션의 격리 수준은 여러 수준으로 구현 가능하다


- Serializable 수준이 가장 높은 수준
- 트랜잭션 동안 선택한 데이터에 대한 병렬 읽기 및 쓰기 쿼리를 차단
- 트랜잭션에서 사용할 수도 있는 데이터 범위에 들어갈 수 있는 데이터에 대한 추가 또는 삭제도 차단


- Repeatable read 수준은 그 다음으로 높은 수준으로, 트랜잭션 동안 선택한 데이터에 대한 읽기 및 쓰기는 차단하지만 트랜잭션 데이터에 포함될 수도 있는 데이터를 추가하거나 삭제하는 것은 허용


- Read Committed는 데이터 쓰기만 차단


- Read Uncommitted는 다른 트랜잭션에 의해 변경되었지만 아직 커밋되지 않은 데이터 읽기도 허용


- 트랜잭션은 RDB처럼 단일 데이터 스토어에서 주로 사용하지만, 데이터베이스나 이벤트 스트림, 질의 시스템 등 여러 시스템 간의 작업이 이루어질 수도 있다.
- DB를 업데이트하면서 메시지 큐에 주문 메시지를 발행한다거나 등을 트랜잭션으로 실행할 필요가 있음
- 이런 경우 XA 트랜잭션이나 Paxos, Raft 등의 동의 알고리즘으로 처리
- 대개 two-phase, three-phase commit 프로토콜로 여러 시스템 간 작업을 처리


#### 어떻게 사용할 수 있나요
- 여러 작업을 단일 작업으로 묶어서 실행
    - 여러 단계의 작업을 묶어서 실행하고, 작업이 모두 성공해야 끝나는 경우 트랜잭션 활용 가능
    - 또한 여러 트랜잭션이 서로를 간섭하지 못하게 한다거나 등
- 여러 시스템 간 협력 작업
    - 이벤트 큐로부터 이벤트를 전달 받고, 이걸 기반으로 데이터 스토어를 업데이트하고, 다른 이벤트 큐에 추가 처리 작업을 전달하는 등을 단일 트랜잭션으로 처리
    - 이를 위해서 two-phase commit 프로토콜을 사용하는 XA 트랜잭션 등을 적용할 수 있다.
    - 대부분의 데이터베이스나 이벤트 큐는 XA 트랜잭션을 지원


![](files/Pasted%20image%2020251008181321.png)


#### 고려해야 할 사항들
- 작업이 단일 단계거나, 여러 단계로 구성되어 있지만 실패해도 문제가 없는 경우 트랜잭션 패턴을 쓰면 안 된다.
- XA 트랜잭션과 같은 합의 알고리즘을 사용하면 작업 동기화하는 데 지연이 발생한다
- 상대적으로 트랜잭션이 짧고 적은 수의 시스템이 연관되는 경우에만 사용


- 또한 가능하다면 작업들이 멱등성을 가지게 만들기
- 그러면 트랜잭션도 필요 없고 시스템도 단순해짐
- 멱등성을 가지만 몇 번이나 실행해도 결과는 똑같다.


- 실행을 동기화하고, 세 개 이상의 시스템이 연계된다면 사가 패턴 쓰는 게 좋다.
- 여러 트랜잭션을 순서대로 실행할 수 있고, 이후 트랜잭션이 실패하면 앞서 실행된 트랜잭션에 대한 보상 작업을 수행한다
- XA 트랜잭션의 분산 잠금으로 인한 높은 지연 시간과 강한 결합성도 낮춰준다.
- 그러나 사가 패턴은 작업이 실패했을 때 모든 트랜잭션이 보상 트랜잭션을 실행할 수 있을 때만 가능하다
- 서드파티 시스템을 통합하는 경우 이게 문제가 될 수도 있다.


- 모든 업데이트가 단일 스토어에서 이루어지거나, 모든 단계가 하나의 원자적 작업처럼 이루어져야한다면 사가 패턴 대신 XA 트랜잭션을 쓰는 게 좋다
- 사가 패턴은 트랜잭션은 순서대로 실행하므로 다른 시스템이 데이터 스토어나 MS에 동시에 접근할 수도 있다
- 이로 트랜잭션 결과가 반영되지 않은 데이터 스토어에서 데이터를 읽어와서 데이터 불일치가 발생할 수도 있다.


#### 관련 패턴들
- 사가 패턴


### 4.8.2 신뢰성 패턴 정리


|패턴|사용하면 좋은 경우|사용해서는 안 되는 경우|이점|
|---|---|---|---|
|**트랜잭션**|• 작업이 여러 단계나 작업으로 구성되어 있으며 모든 단계가 성공해야 해당 작업이 올바르게 끝났다고 볼 수 있는 경우|• 작업이 한 단계로 이루어진 경우<br>• 애플리케이션 작업이 여러 단계로 이루어져 있지만 몇몇 단계가 실패해도 문제가 되지 않는 경우|• ACID 속성을 따름<br>• 여러 독립적인 트랜잭션을 처리할 수 있음|


## 4.9 보안: 볼트 키 패턴
- vault key pattern은 신뢰할 수 있는 토큰을 가지고 데이터 스토어에 직접 접근할 수 있게 해줍니다.
- 이 토큰을 vault key라고 부른다


#### 어떻게 동작할까요
- 클라가 제출하는 신뢰할 수 있는 토큰에 기반해서 동작
- 이 토큰은 데이터 스토어가 검증
- 볼트 키 패턴에서는 애플리케이션이 누구에게 어떤 데이터를 접근할 수 있을지 결정


![](files/Pasted%20image%2020251008182715.png)


- 클라 혹은 서비스 호출 측은 데이터 스토어에 접근할 수 있는 토큰을 요청
- 애플리케이션이 스스로 ID Provider로 동작하거나 다른 ID Provider에게 접근해서 서비스 호출자를 확인하고 데이터 스토어에 접근할 수 있는 볼트 키를 생성하고 제공
- 애플리케이션은 또한 서비스 호출 측이 데이터 스토어에서 수행할 수 있는 작업 범위를 지정할 수 있고
- 유효 기간을 지정하는 것도 가능


- vault key의 유효 시간 동안 refresh token을 통해 새로운 볼트 키를 발급받는 것도 가능


#### 어떻게 사용할 수 있나요
- 데이터 스토어가 데이터를 접근하고자 하는 클라이언트를 인증하고 확인하기 위해 id provider에게 접근할 수 없을 때 사용 가능
- 데이터 스토어는 id provider에 대한 인증서를 보관하고, 클라가 제출하는 볼트 키를 id provider에 접근하지 않고도 복호화하고 인증할 수 있다
- 토큰 검증을 위한 원격 서비스 호출도 필요하지 않으므로 최소한의 지연 시간으로 클라이언트를 인증할 수 있다.


#### 고려해야 할 사항들
- 서비스 호출측이 한 번 데이터 스토어에 대한 접근 권한을 얻고 나면 애플리케이션은 이를 제어할 수 없다
- 즉, 이 패턴을 사용하면 데이터 스토어에 대한 세부 제어 없이 접근하게 만들면서 보안을 강제할 수 있다
- 단, 데이터 스토어가 키를 검증할 수 있는 경우에만 이 패턴을 써야 한다.
- 또한 접근 시 사용하는 토큰이 id provider에 발급되었는지, 유효 시간이 지나지 않았는지도 검증해야 한다.
- 몇몇 스토어는 접근 범위를 지정하는 것도 가능하다
- 데이터 스토어가 키에 기반한 데이터 접근을 검증할 수 없다면 데이터 스토어 앞에 API 보안 등의 기능으로 보호할 수 있는 데이터 서비스를 두는 게 좋다.


- 어떤 경우 악의적인 사용자가 볼트 키를 가로채거나 위조할 수도 있다.
- 대부분의 데이터 스토어가 가로챈 토큰이나 위조 토큰을 사용하는 것을 막는 기능을 제공하지 않기 때문에 이를 막는 건 거의 불가능하다
- 따라서 볼트 키의 유효시간을 적절한 값으로 지정해야 한다.


#### 관련 패턴들
- 데이터 서비스 패턴과 연관되어있다.


### 4.9.1 볼트 키 패턴 정리


|패턴|사용하면 좋은 경우|사용해서는 안 되는 경우|이점|
|---|---|---|---|
|**볼트 키**|• 최소한의 지연 시간으로 데이터에 안전하게 접근하고자 할 때<br>• 데이터 스토어가 서비스 호출에 대한 인증 및 권한 검사를 할 수 있을 만큼 충분한 연산 능력을 가지지 못하는 경우|• 세밀한 데이터 보호가 필요한 경우<br>• 질의가 데이터 스토어에서 실행되며 고성능성을 요구하는 경우<br>• 외부에 노출한 데이터 스토어가 키에 기반한 접근 검증을 할 수 있는 경우|• 볼트 키를 통해 데이터 스토어에 안전하게 직접 접근할 수 있음<br>• 데이터 접근 검증을 위해 중앙 ID 확인 서비스를 호출하는 것보다 적은 비용으로 검증할 수 있음|


## 4.10 데이터 관리 패턴 구현 기술
- 상황에 맞는 적절한 기술 선택 필요
- 적절한 데이터 스토어 선택 필요
- 어떤 데이터를 저장하는지, 데이터 크기는 어느 정도인지, 기대하는 읽기 및 쓰기 성능은 어느 정도이며 시스템의 가용성과 확장성, 일관성을 고려해야 한다.


### 4.10.1 관계형 데이터베이스 관리 시스템
- 대부분의 전통적인 DB는 RDBMS
- MySQL, Oracle, MSSQL, Postgres, H2 등
- ACID 속성 제공, SQL 지원
- XML, JSON, 바이너리 데이터 등은 잘 맞지 않아 분산 파일 시스템이나 NoSQL 등을 쓰는 게 좋다.


- 클라우드 네이티브 애플리케이션을 만들 때는 직접 DB를 배포하는 것보다 관리형 RDBMS를 쓰는 게 좋다.
- 복잡한 관리에 대한 부담을 덜 수 있고, 더 잘 조율된 환경을 제공받을 수 있다.


- 확장하려면 주 데이터베이스와 복제 데이터베이스를 나누거나, 샤딩한다.
- 저장 공간이 부족하면 주기적으로 오래된 데이터를 백업하거나 드물지만 NoSQL 등에 아카이브를 저장하고 해당 데이터를 DB에서 삭제할 수도 있다.


### 4.10.2 아파치 카산드라
- 분산 NoSQL DB
- 페이스북 내부에서 사용하다가 오픈소스로 전환됨
- 카산드라 column store은 zero-down time으로 유명하다
- 높은 성능, 선형적인 확장성 등 최신 요구사항도 지원
- 데이터 센터 간 데이터 복제, 리전 간 데이터 복제도 지원
- 페타바이트 단위의 데이터를 다룰 수 있고, 초당 동시 수 천개의 작업을 처리 가능


- 쓰기 성능은 읽기 성능보다 좋다
- 설계 특성 상 약한 일관성을 제공
- 단, 일관성 수준을 변경해 애플리케이션에 따라 약한 일관성이나 강한 일관성 모두 구현 가능


- 성능은 데이터를 어떻게 저장하고 질의하는지에 따라서도 달라진다
- 키 집합에 근거한 질의 데이터를 사용하면 파티션 키를 사용해야 한다
- 서로 다른 여러 키로 질의하는 경우 부 인덱스를 만드는 게 좋다
- 너무 많이 사용하면 매번 인덱스를 업데이트해야 하기 때문에 느려질 수 있다
- 또한 두 개의 컬럼을 조인하는 게 비효율적이며, 데이터를 자주 업데이트하는 경우에도 그다지 좋지 않다.


### 4.10.3 아파치 HBase
- 확장 가능한 분산 NoSQL 컬럼 스토어
- HDFS에서 동작
- 수십만 개의 행과 수백만개의 열을 가지는 아주 큰 테이블도 처리 가능
- 하둡 데이터에 대한 실시간, 랜덤 읽기/쓰기 접근을 제공
- 아주 큰 데이터 셋에 대해서도 선형적인 확장성을 제공하며 서로 다른 구조나 스키마를 가지는 데이터 원천도 쉽게 조합 가능


- 컬럼 스토어이므로 동적 데이터베이스 스키마를 지원하고, HDFS에서 동작하므로 map-reduce도 가능
- 그만큼 HBase는 다른 시스템에 상호 의존적이며 설정이나 보안, 유지 관리가 어렵다.


- 카산드라와 달리 HBase는 master/worker 배포를 사용하므로 SPoF를 지닌다.
- 따라서 고가용성이 필요한다면 HBase 대신 카산드라를 써라
- 데이터 일관성을 중요시하면 HBase가 더 낫다
- HBase는 데이터가 위치해야 하는 한 곳에만 데이터를 저장하며, 데이터 복제는 외부에서 HDFS에 의해 이루어진다.
- 카산드라처럼 데이터가 자주 삭제되거나 변경되는 경우 사용이 어렵다.


### 4.10.4 몽고DB
- 도큐먼트 스토어로 JSON 등을 저장
- 도큐먼트와 컬렉션은 RDB의 레코드와 테이블과 비슷
- Mongodb 쿼리 언어로 데이터 접근 가능.
- 필드에 대한 집계, 필터, 정렬 등이 가능
- 도큐먼트 구조를 바꾸지 않고 필드를 추가하거나 삭제하는 것도 가능


- 몽고는 인덱스에 더 민감함
- 인덱스가 없으면 성능이 떨어지고 컬렉션 전체를 검색해야 함
- 가용성보다 데이터 일관성을 중요시
    - 가용성은 주 스토어에서만 가능한 읽기 및 쓰기, 여러 개의 복제로 이루어짐
    - 주 스토어가 사용이 불가능한 경우 읽기 및 쓰기 작업은 10~40초 가량 중단되고 그동안 복제 스토어 중 하나를 주 스토어로 선출


- 모바일 애플리케이션, 콘텐츠 관리, 실시간 분석, IoT 애플리케이션에서 많이 사용
- JSON 도큐먼트를 분명하게 나타낼 수 있는 뚜렷한 스키마가 없고 데이터 스토어 일부를 사용하지 않아도 문제가 없을 때 쓰면 좋다
- 트랜잭션에 적합하지는 않다


### 4.10.5 레디스
- 인메모리 키-값 데이터베이스
- 캐시를 저장하는 방법으로 많이 사용
- 문자열 키는 물론 목록, 집합, 정렬된 집합, 해시, 비트 배열 등 여러 값을 저장 가능
- 그래서 내부 데이터 구조를 그대로 레디스에 저장할 수 있어서 애플리케이션이 간단해짐
- 트랜잭션 지원하고, 키에 대한 TTL 설정이나 LRU에 따른 키-값 삭제, 자동 복구, 넘치는 데이터를 disk에 저장 등의 기능 제공


- RDB(Redis Database Backup), AOF(Append Only File) 등으로 데이터를 영구 저장할 수 있음
- 두 가지 방법을 잘 쓰면 좋은 쓰기 성능을 유지하면서 시스템 장애 상황에서 데이터 안정성을 적절한 수준으로 확보할 수 있음


- 단일 마스터 노드와 여러 개의 복제 노드로 고가용성 구현
- 데이터 샤딩을 통한 확장성도 제공


- 단, 질의 처리나 복잡한 데이터 처리, 데이터 집계 등의 기능이 없으므로 NoSQL 대체품으로는 부적절


### 4.10.6 아마존 dynamoDB
- key-value document store로 낮은 지연시간과 높은 확장성 제공
- 하루에 수십 조 개의 요청, 초당 2천만 개 이상의 요청을 처리 가능
- SSD에 저장되고, 자동으로 파티션이 나뉘며 여러 AZ에 복제됨
- 세밀한 데이터 접근 제어 제공
- 검증된 보안 기법을 통해 사용자 인증, 인가


- AWS 서비스이므로 로컬 서버나 다른 클라우드에 설치해서 사용은 불가능
- 테이블 조인, 외래 키 등의 기능은 제공하지 않아 질의 기능에 제약이 있음
- 대신 비정규화된 중복 데이터로 성능 향상


### 4.10.7 아파치 HDFS
- 분산 파일 시스템
- 비교적 저렴한 하드웨어에서 실행하더라도 최소 세 개의 복제본을 분산 저장함으로써 높은 데이터 탄력성을 가지도록 설계
- 데이터는 변경이 불가능
- 데이터를 스트림 방식으로 읽고 쓰는 데 최적화되어 있어 분산 데이터 저장할 때 주로 사용
- Hadoop Map-Reduce 작업에서 대용량 데이터 효과적으로 처리하기 위해서 사용


- 데이터를 여러 노드에 저장, 데이터에 대한 모든 메타 데이터를 단일 네임 노드의 메모리에 저장
- 해당 노드에 장애가 발생하면 새로운 읽기 및 쓰기를 할 수 없고 시스템을 사용할 수 없음
- 네임 노드의 메모리 크기에 따라 저장할 수 있는 파일 수에 제한이 생김
- 따라서 크기가 작은 파일을 많이 저장하는 것보다 크기가 큰 적은 수의 파일을 저장하는 게 좋음
- 순차적 읽기에 최적화되어 랜덤 액세스가 필요한 경우에는 그닥 적합하지 않음


### 4.10.8 아마존 S3
- AWS object storage
- data lake, 스토리지, 데이터 백업, 아카이브, 빅데이터 분석 등에 사용
- Athena의 SQL로 데이터 노드에서 분석 작업을 실행하는 데이터 지역성 패턴도 지원
- S3 Select로 일부 데이터만 읽는 것도 가능
- 이를 통해 데이터 접근 성능을 최대 4배 향상 가능


- 매우 높은 가용성 제공, 세밀한 데이터 접근 제어 기능


### 4.10.9 애저 코스모스DB
- 완전 관리형 NoSQL 데이터 스토어
- key-value, document, column, graph로 사용 가능
- 낮은 지연 시간
- 단말 간 암호화, 접근 제어 등의 보안도 제공
- mongo db나 카산드라를 위한 API도 제공해서 애플리케이션 수정 없이 사용 가능


- azure가 제공하는 서비스라 로컬 서버나 azure가 아닌 다른 클라우드에서 사용 불가능
- 온프레미스 카산드라 클러스터에서 데이터를 이전하고 동기화하는 방법 제공
- 트랜잭션 지원하지만 논리적 데이터 파티션 내에서만 가능하다는 제약이 있음


### 4.10.10 구글 클라우드 스패너
- 완전 관리형 RDB
- 무한한 크기 확장, 강력한 일관성 제공
- SQL 지원, 클러스터 모든 노드에서의 트랜잭션 지원
- 읽기 및 쓰기 트랜잭션을 선형으로 확장 가능
- 데이터 계층에 대한 암호화, 접근 제어를 통한 보안


- 구글만 지원
- SQL 지원하지만 ANSI SQL 모두 지원하지는 않음


### 4.10.11 구현 기술 정리


| 데이터 스토어                       | 사용하면 좋은 경우                                                                                                                                                     | 사용해서는 안 되는 경우                                                                                                       |
| ----------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| **관계형 데이터베이스 관리 시스템 (RDBMS)** | • 트랜잭션과 ACID 속성이 필요한 경우<br>• 데이터 간 상호 관계를 유지해야 하는 경우<br>• 적거나 중간 정도 양의 데이터를 다루는 경우                                                                             | • IoT 데이터와 같이 데이터가 계속 증가하는 경우<br>• XML이나 JSON, 이진 데이터 포맷과 같은 데이터를 처리하는 경우<br>• 애플리케이션에서 일정 수준 이상의 가용성을 요구하는 경우      |
| **아파치 카산드라**                  | • 고가용성이 필요한 경우<br>• 높은 확장성이 필요한 경우<br>• 중앙화되지 않은 솔루션이 필요한 경우<br>• 읽기보다 쓰기가 빨라야 하는 경우<br>• 데이터 조회가 대부분 파티션 키를 통해 이루어지는 경우                                       | • 기존의 데이터가 자주 변경되는 경우<br>• 파티션 키에 해당하지 않는 컬럼으로 데이터에 접근해야 하는 경우<br>• 트랜잭션이나 복잡한 조인 연산, ACID 속성과 같은 관계형 기능을 필요로 하는 경우 |
| **아파치 HBase**                 | • 일관성이 필요한 경우<br>• 확장성이 필요한 경우<br>• 증강화되지 않은 솔루션이 필요한 경우<br>• 높은 읽기 성능이 필요한 경우<br>• 랜덤 접근 또는 실시간 데이터 접근이 필요한 경우<br>• 페타바이트 단위의 데이터를 저장해야 하는 경우                 | • 애플리케이션이 일정 수준 이상의 기능성을 요구하는 경우<br>• 기존의 데이터가 자주 변경되는 경우<br>• 트랜잭션이나 복잡한 조인 연산, ACID 속성과 같은 관계형 기능을 필요로 하는 경우      |
| **몽고DB**                      | • 일관성이 필요한 경우<br>• 증앙화되지 않은 솔루션이 필요한 경우<br>• 도큐먼트 스토어가 필요한 경우<br>• 여러 키를 통한 데이터 검색이 필요한 경우<br>• 높은 쓰기 성능이 필요한 경우                                               | • 애플리케이션이 일정 수준 이상의 기능성을 요구하는 경우<br>• 트랜잭션이나 복잡한 조인 연산, ACID 속성과 같은 관계형 기능을 필요로 하는 경우                               |
| **레디스**                       | • 확장성이 필요한 경우<br>• 인-메모리 데이터베이스가 필요한 경우<br>• 데이터 복구를 위해 영구히 저장할 수 있어야 하는 경우<br>• 캐시나 큐, 실시간 스토리지가 필요한 경우                                                       | • 복잡한 연산을 통한 저장 및 질의가 가능한 전통적인 데이터베이스가 필요한 경우                                                                       |
| **아마존 다이나모DB**                | • 높은 확장성이 필요한 경우<br>• 도큐먼트 스토어가 필요한 경우<br>• 키-값 스토어가 필요한 경우<br>• 높은 쓰기 성능이 필요한 경우<br>• 세밀한 접근 제어가 필요한 경우                                                       | • AWS가 아닌 다른 클라우드를 사용하는 경우<br>• 트랜잭션이나 복잡한 조인 연산, ACID 속성과 같은 관계형 기능을 필요로 하는 경우                                     |
| **아파치 HDFS**                  | • 파일 시스템이 필요한 경우<br>• 큰 파일을 저장하는 경우<br>• 데이터를 한 번 저장하고 여러 번 읽는 경우<br>• 파일에 대한 랜덤액세스 작업을 처리하는 경우<br>• 확장성이 필요한 경우<br>• 데이터 탄력성이 필요한 경우                          | • 크기가 작은 파일을 저장하는 경우<br>• 파일 내용을 변경해야 하는 경우<br>• 랜덤 데이터 읽기가 필요한 경우                                                  |
| **아마존 S3**                    | • 오브젝트 스토리지가 필요한 경우<br>• 오브젝트에 대한 랜덤액세스 작업을 처리하는 경우<br>• 높은 확장 기능이 필요한 경우<br>• 오브젝트 데이터의 일부만 읽어야 하는 경우<br>• 세밀한 접근 제어가 필요한 경우                                  | • AWS가 아닌 다른 클라우드 플랫폼을 사용하는 경우<br>• 복잡한 질의를 처리해야 하는 경우                                                              |
| **애저 코스모스DB**                 | • 높은 확장 기능이 필요한 경우<br>• 도큐먼트 스토어가 필요한 경우<br>• 키-값 스토어가 필요한 경우<br>• 그래프 스토어가 필요한 경우<br>• 컬럼 스토어가 필요한 경우<br>• 세밀한 접근 제어가 필요한 경우<br>• 몽고DB와 카산드라 클라이언트 연결이 필요한 경우 | • 애저가 아닌 다른 클라우드 플랫폼을 사용하는 경우<br>• 여러 데이터 파티션에 걸친 트랜잭션이 필요한 경우                                                      |
| **구글 클라우드 스패너**               | • 높은 확장 기능이 필요한 경우<br>• 관계형 스토어가 필요한 경우<br>• SQL 질의 처리가 필요한 경우<br>• 클러스터의 모든 노드에 대한 트랜잭션 지원이 필요한 경우                                                            | • 구글 클라우드가 아닌 다른 클라우드 플랫폼을 사용하는 경우<br>• ANSI SQL 스펙 지원이 필요한 경우                                                      |


## 4.11 테스팅
- 데이터 스토어는 데이터 서비스와의 상호작용을 통해 테스트 가능
- 데이터 서비스의 로직은 복잡할 수도 있고 간단할 수도 있음. 애플리케이션의 병목이 되기도 함
- 아래 사항을 잘 지킨다면 이런 문제 해결 가능
    - 테스트는 깨끗하고 미리 생성된 데이터 스토어에서 이루어져야함. 테스트는 데이터를 초기화하고, 작업 간 데이터 일관성이 유지되는지 확인하는 코드로 이루어져야함
    - 모든 데이터 스토어 타입과 버전을 테스트해서 발생할 수 있는 예외 상황을 확인해야 함. 테스트를 위한 데이터 스토어를 도커로 만들어서 여러 환경 테스트를 할 수 있음
    - 데이터 맵핑을 테스트해서 데이터 스토어를 사용할 때 모든 필드가 제대로 맵핑되는지 확인해야 함
    - 서비스가 데이터 삽입이나 쓰기, 삭제, 변경과 같은 작업을 할 때 데이터 서비스에 직접 접근할 수 있는 테스트 클라이언트를 통해 데이터 스토어의 상태를 점검해야 함
    - relational constraint, trigger, stored procedure 등도 확인해야 함


- 실제 운영 환경과 비슷한 상황에서 여러 클라이언트를 사용한 부하 테스트를 진행하는 게 좋다
- 클라우드 네이티브 마이크로서비스 테스트하는 경우 실제 데이터 스토어 배포 없이 mockup 서비스 API로 테스트하기도 한다.


## 4.12 보안
- 보안은 물리적, 그리고 소프트웨어 적으로 적용할 수 있음
- 데이터 서버는 반드시 보호해야 하고, 인가된 인원만 접근 가능해야 함
- 서버에서 실행되는 데이터 스토어는 vault key나 API 보안 등으로 접근 제어
- 민감한 데이터를 저장하는 경우 데이터 스토어에 저장하기 전 암호화
- 데이터가 저장되는 파일 시스템을 암호화해서 추가적인 보호장치 마련


- 민감한 데이터는 다른 데이터와 격리해서 추가 보안 정책 적용, 감사, 모니터링
- 필요없는 민감 정보는 수집하고 저장하지 마라.
- 마스킹은 민감한 정보를 고유한 식별자로 대체하고, 식별자에 대해 매핑되는 민감 정보를 보호되는 데이터 스토어에 저장


- 메시지를 나누지 않고도 민감 정보를 보호하고 싶다면 민감 정보만 암호화


## 4.13 관측 가능성 및 모니터링
- 지표, 로그, 분산 추적 등
- 데이터 스토어의 성능을 측정, 애플리케이션의 변경 또는 부하 등으로 성능 지표에 차이가 보이면 이를 수정
- 대부분의 애플리케이션에서 들어오는 요청은 데이터 스토어와 상호작용
- 데이터 스토어의 성능 문제, 가용성 문제는 전반적인 시스템에 문제를 일으키고 사용자 경험에 악영향을 끼침


- 아래 지표를 관찰
    - 애플리케이션 메트릭
        - 데이터 스토어 가동시간, 상태
        - 질의 처리 시간
            - 비효율적인 질의
            - 데이터 스토어의 데이터 증가
            - 동시성
            - CPU/메모리, 디스크 공간 등 시스템 자원의 부족
            - 의존 시스템 또는 복제본이 사용 불가능한 상태
        - 질의 실행 응답 : 질의 처리가 제대로 동작하는지 확인
        - 질의 작업 감사 : 이상한 질의나 사용자 작업은 예상하지 못한 결과를 초래하고, 성능에 악영향을 줄 수 있음. 로그로 이를 식별하고 방지
    - 시스템 지표 : CPU 점유율, 메모리, 디스크 공간, 네트워크, I/O 등 충분한 시스템 자원이 있는지 확인
    - 데이터 스토어 로그
    - 주 데이터스토어와 복제 데이터 스토어 간 통신에 소요되는 시간, 처리량


- 지표를 분석할 때 과거와 현재 지표를 비율로 계산해서 비교할 수 있음
- 백분위 값으로 비교하면 이상한 동작이나 분포들을 분명히 볼 수 있음


## 4.14 데브옵스
- 데이터 스토어를 배포하고 관리할 때는 다음을 고려
    1. 사용할 데이터 스토어 유형 정하기
    2. 배포 패턴 설정
        - 다음을 고려하여 고가용성, 확장성 수준 설정
            - 클라이언트 유형은?
            - 얼마나 많은 노드를?
            - 데이터 스토어를 벤더 사용? 자체 관리?
            - 복제는?
            - 데이터 백업은?
            - DR은?
            - 데이터 보호는?
            - 데이터 스토어 어떻게 모니터링?
            - 데이터 스토어 관리 비용 어느 정도?
    3. 데이터 보호 정책 적용
        - 물리적, 소프트웨어적으로 보호
        - 접근 제어, 데이터 암호화, 로그 감사 등
    4. 관측 가능성을 확보하고 모니터링 설정
        - 데이터 스토어도 모니터링 가능
        - 샤드 재배치 , 데이터 확장 문제 등을 찾거나
        - 애플리케이션의 성능 및 확장성을 향상시킬 수 있는 다른 디자인 패턴 적용
    5. 자동화된 지속적인 전달 사용
        - 스키마를 처음 초기화하고, 하위 호환성을 유지하는 게 쉬운 일이 아님
        - 하위 호환성이 없으면 매끄러운 업데이트나 실패시 롤백이 불가능
        - 생산성을 올리려면 스크립트 등을 통해 지속적인 전달 자동화가 필요
        - 배포나 검증, 운영 등 다양한 배포 환경을 만들고 각각을 격리해서 실제 운영 환경에 애플리케이션을 배포하기 전 충분히 검증을 거쳐야 함


## 4.15 마치며


