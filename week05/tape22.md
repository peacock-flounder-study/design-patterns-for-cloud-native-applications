# 4장

### 데이터 관리

- 데이터 스토어를 배포하고 관리하는 방법(중앙화 / 분산)
- 애플리케이션이 데이터를 공유하는 방식

**중앙 데이터 관리**

- 전통적인 데이터 중심 애플리케이션에서 사용하는 방식
- 모든 데이터를 단일 DB에서 관리하여 정규화, 데이터 일관성을 챙길 수 있음
- 보안 정책을 강제하거나 정보 접근 권한에 대해 통제하는 것이 편리함
- 하지만 DB와 강결합되면서 애플리케이션을 독립적으로 개선할 수 없기 때문에 클라우드 네이티브 애플리케이션에서는 피해야함

**분산 데이터 관리**

- 마이크로서비스마다 별도의 데이터 스토어를 사용
- 크기를 조절하거나 팀 별로 관리하기가 편해짐
- 각 서비스 별로 적합한 데이터 스토어를 사용할 수 있음
    - 결제는 관계형, 조회는 도큐먼트, 장바구니는 분산 key value

**하이브리드 데이터 관리**

- 분산 데이터 관리는 서비스 별로 데이터 스토어를 관리하는 것이 부담
- 여러 마이크로 서비스가 데이터베이스를 공유하며 같은 바운디드 컨텍스트 내에 존재하는 하이브리드 데이터 관리 방식을 채택
    - 다른 서비스가 DB에 직접 접근하지 않도록 주의해야함
    - 현재 팀에서는 결제 서비스에서 주문 DB를 직접 업데이트하고있는데, api call로 업데이트치도록 분리해야함(도메인이 분리되었음)

### 데이터 조합 패턴

- 서비스 부하를 고려하여 캐시를 두면 조회 성능을 개선할 수 있음

**데이터 서비스 패턴**

- 데이터 서비스가 요청을 받아서 DB에서 데이터를 조회하고 응답을 만드는 작업을 담당함
- 여러 클라이언트에 다양한 조합으로 데이터를 제공할 수 있으며
- 보안 기능을 적용하고, 정책 기반으로 리소스 제한을 두어 시스템 문제가 있어도 핵심 서비스만 데이터에 접근하도록 구성할 수 있음
- 테이블 join 연산이나 프로시저, 캐시 등을 통해 작업을 효율화할 수 도 있음
- 여러 마이크로서비스가 데이터에 접근하거나, 클라우드 네이티브 애플리케이션에서 레거시나 전용 데이터스토어를 사용할 수 있도록 추상화할 때 이 패턴을 사용할 수 있다.
    - 관리형 API를 통해 데이터를 접근하게 하면 마이크로서비스 간 연관성을 느슨하게 할 수는 있으나
    - 특정 마이크로 서비스가 데이터와 분명한 연관성이 있는 경우 불필요한 마이크로서비스가 생기는 셈이라 이 점을 고려해야함
- 캐싱, 성능 최적화, materialized view, 볼트 키 패턴

**조합 데이터 서비스 패턴**

- 하나 이상의 데이터 서비스로부터 데이터를 읽어서 조합 (서버 사이드 매시업 패턴으로도 불림)
<img width="407" height="614" alt="Screenshot 2025-10-23 at 8 05 56 PM" src="https://github.com/user-attachments/assets/527381f6-758a-4c7b-9e1d-b234c000130b" />



- 여러 마이크로서비스가 비슷한 데이터 조합 패턴을 사용하는 경우, 각 서비스마다 조합하지 않고 공통 서비스 형태로 묶어서 제공하면 중복 작업을 줄일 수 있음
    - 예) 상품 제공업체로부터 데이터를 받아 상품 목록을 제공하는 공통 서비스를 만들면 → 여러 마이크로서비스들이 가공 중복작업을 할 필요가 없음
    - 그림 상으로는 마치 마이크로서비스가 데이터베이스 접근할 때 무조건 조합 데이터베이스를 거치는 것처럼 되어있지만 혼용하는 경우가 많지 않을까? 이렇게만 쓰는 케이스가 더 있을까요?

**클라이언트 사이드 매시업 패턴**
<img width="306" height="525" alt="Screenshot 2025-10-23 at 8 06 08 PM" src="https://github.com/user-attachments/assets/f0d7f522-e655-419d-87f1-f2f11a5d72cd" />



- 웹 클라이언트가 마이크로서비스 들에서 데이터를 가져와 조합하는 형태 (ajax)
    - RIA(rich internet application)
        - SPA(페이지 전체로딩, 일부만 동적으로 변경 gmail, notion), MPA(요청마다 다시 랜더링, 쇼핑페이지 ),PWA(앱처럼 설치가능한 웹앱)
- 간략한 데이터는 즉시 표시하고 세부 데이터는 나중에 표현하는 등
- 콘텐츠를 동기적으로 가져와서 데이터를 조합하는 경우에 사용
    - 아마존 상품 상세 페이지에서 중요한 기본 이미지와 상품 정보를 미리 표시하고, 나머지 정보나 리뷰는 ajax 호출로 불러오면서 동적으로 웹페이지 업데이트
- 데이터의 일부분을 사용자에게 바로 보여줄 수 있거나, 그 데이터가 의미있게 사용되는 경우에 이 패턴을 적용

---


### **데이터 확장 패턴**

어떻게 데이터 스토어를 확장해서 최적화할 수 있나?

**샤딩 패턴**

데이터 스토어를 샤드로 나누어서 데이터 저장 및 읽기 규모를 자유롭게 조절하는 패턴으로

속성에 따라 분할되며, 어떤 샤드에 데이터가 위치하는지 쉽게 알아낼 수 있음.

- 수평적 : 같은 스키마를 사용하면서 샤딩 키에 따라 다른 데이터레코드를 가짐 (id 해시값을 기준으로 데이터를 샤딩해서 분산저장)
- 수직적(hot-cold) : 아예 다른 스키마로 다른 데이터를 가지는 경우
    - 데이터 접근 빈도에 따라 나눌 때 좋다
- 기능적(heavy) : 제공하는 기능 별로 다른 샤드에 데이터를 분리
    - 상품 세부정보와 리뷰정보를 나누어서 데이터 샤딩

=> 수직이나 기능적 샤딩은 데이터를 분리하는데 한계가 있어 결국엔 수평으로 샤딩하는 방법을 사용할 수 밖에 없는 시점이 옴

**데이터를 어디에 저장할 것인가?**

- 디렉토리 기반 샤딩
    - 검색 서비스나 분산 캐시를 통해 샤드 키와 실제 데이터 위치 정보 저장
    - 애플리케이션에서 샤드 키를 통해 데이터가 저장된 위치를 검색해서 데이터를 조회
        - 데이터가 재배치되는 경우 클라이언트는 다시 샤드 키를 통해 위치를 검색해야함
- 범위 기반 샤딩
    - 샤딩 키 값이 연속적, 날짜나 시간
    - 날짜나 시간에 따라 데이터를 나누고 저장할 때 유용함
- 해시 기반 샤딩
    - 샤드 간 데이터를 균일하게 분배하고자 하면 해시기반
        - 데이터 필드나 날짜 범위로 나누면 데이터가 항상 균등하게 배분되지는 않기 때문에
        - 만약 더 균일하게 나누고자 한다면 해시 기반으로 데이터를 샤딩
    - 샤드 키로 해시 값을 만들어서 이 값을 기반으로 데이터 샤드 위치를 정함
    - 범위 단위보다는 개별 데이터 질의에 유용함

⇒ 샤드 패턴은 시스템의 디스크 공간이나 RAM, 스토리지나 연산, 네트워크 대역폭 등의 자원이 확장되는데는 한계가 있기 때문에 멀티 노드로 확장될 때 유용하다.

**데이터 필드를 조합해서 샤드 키를 만들수도 있음**

- 옷 type/brand (주 샤드 키) 인덱스도 만들 수 있음
- 날짜 시간 범위로도 만들 수 있음
    - hot shard,나머지는 archive
- 지리적으로 클라이언트가 분산되어있으면 데이터 역시 지역에 따라 나눌 수 있음

→ 데이터 샤딩 패턴에서 고려할 점은 최대한 균등하게 부하가 고르게 분산되도록 만들어야한다는 것

→ 데이터 추가, 삭제, 질의방식 변경을 할 때 샤드 불균형은 언제든 발생할 수 있고, 재배치하려면 시간이 걸림

→ 그래서 효과적으로 재배치를 하려면 샤드 크기를 가급적 작게 유지하는 것이 좋다~

- 여러 샤드 간 데이터 aggregate 처리도 종류별로 다르다(max, avg, min…) 각 샤드 별로 결과를 반환해서 결과를 조합함
- 중앙 값은 샤딩된 데이터만으로는 어려움

샤드 키는 auto increasement값은 피해야함(동일한 샤드 키가 생성될 수 있으며 서로다른 데이터를 같은 키로 참조하는 일이 발생할 수 있다)

**CQRS 패턴**

- 쓰는 DB랑 읽기용 DB를 분리하는 것
    - 변경 내용은 비동기로 전달됨, 질의 서비스는 이 데이터 모델을 토대로 데이터를 만든다.
    - <img width="462" height="284" alt="Screenshot 2025-10-23 at 8 06 27 PM" src="https://github.com/user-attachments/assets/cf61b2c4-5905-4b2d-8641-d100f02d5f93" />
- 명령과 질의에 서로 다른 도메인 모델을 사용하고
- 성능이나 보안 문제로 데이터 변경/읽기를 분리하고자 할 때 사용하는 패턴
    - 상품 세부정보와 재고를 관계형 DB에 저장
        - 구매할 때(쓰기) 재고 정보를 갱신하는데는 효과적이나
        - 상품 상세 페이지에서 이 데이터들을 묶어서 변환할 때는 시간이 오래걸림
    - CQRS 패턴을 적용하면 비동기 질의 데이터 셋을 만들고
        - 이를 json 도큐먼트 스토어에 저장해둔 다음 읽기에서 이 데이터 스토어를 사용하면 최적화할 수 있음
        - 명령과 질의 모델이 강결합되어있지 않아서 각 모델을 독립적으로 발전하고 다른 팀에서 만들 수도 있음
    - 또한 클라우드 네이티브 애플리케이션에서 보안성 검증, 메시지 변환과 같이 높은 성능을 요구하는 데이터 쓰기 작업, 복잡한 join이나 데이터 매핑 시에도 적용 가능

- CQRS 패턴은 높은 가용성을 제공하나, 이벤트 소싱과 같은 패턴으로 질의 스토어에 전달되기 때문에 약한 일관성이어도 무관한 서비스에 사용해야함.
- 또한 명령/질의 모델이 분리되므로 ORM 과 같은 자동화 도구를 사용할 수 없음
    - 대개 DB를 사용해서 조합모델을 만들기 떄문에 CQRS패턴을 적용하려면 생성된 모델을 직접 수정하거나 바닥부터 만들어야함
- 패턴을 적용하면 시스템 구조가 매우 복잡해지는 점도 고려해야함
    - 이벤트 소싱 패턴 등으로 데이터 소스가 변경되는 걸 관리하고,
    - 중복이나 실패 이벤트 처리도 신경써야함
    - 그럼 언제 사용하지?

---

### **성능 최적화 패턴**

분산 환경에서 데이터는 병목 현상의 주요 원인이 됨

- 일관성 등의 요구사항으로 인해 데이터 락을 얻기 위한 경합이 발생하기도 하고
- 분산 데이터 간의 동기화 부하도 생김
- 그래서 성능 향상을 위해서는 인덱스를 만들거나, 데이터 비정규화와 CQRS 패턴 등을 함께 사용할 수 있음
    - 이런 기법들 외에도 데이터 처리하는 곳 가까이에 저장하거나,
    - 전송하는 데이터 양을 줄이거나 전처리하는 방식으로 성능을 향상할 수도 있음

**구체화된 뷰 패턴 (materialized view pattern)**

- 데이터를 처리하는 곳 가까운 곳에 미리 구체화된 뷰로 저장하여
- 질의에 대한 데이터 조회를 효과적으로 처리하는 방법
- 서비스와 관련된 모든 데이터를 로컬 데이터 스토어에 저장하고, 데이터 포맷을 질의에 최적화된 형태로 변경하는 패턴

<img width="637" height="399" alt="Screenshot 2025-10-23 at 8 06 47 PM" src="https://github.com/user-attachments/assets/055d1329-7b70-4ab1-bc09-b08f9f25da38" />
- 이 패턴은 의존 서비스로부터 데이터를 비동기로 복제해서 사용하는데,
    - DB 에서 지원하는 기능을 사용하거나, 이벤트 소싱 패턴으로 이벤트를 받아 데이터를 복제하면
    - 이 이벤트는 해당 서비스의 데이터를 가져와 구체화된 뷰를 만들어서 사용하는 방식
- 마이크로서비스는 해당 데이터를 복제해서 로컬 스토어에 저장하는 방식

- 복잡한 조인 연산을 제거하고 서비스 결합도를 낮추는 장점이 있음
    - 데이터 일부를 로컬에서 처리하고
    - 나머지는 지연 시간이 긴 외부 데이터를 소스에서 가져와도 무방할 때 주로 사용함
    - 예) 상품 상세페이지의 리뷰나 별점 데이터는 미리 조회해서 로컬 스토어에 복제하여 씀
    - 보안에 민감하지 않은 데이터들은 미리 복제해서 제공하면 불필요한 검사나 검증을 피할 수 있음

**데이터 지역성 패턴**

- 데이터 처리 로직을 최대한 데이터 가까운 곳에서 실행하는 것
    - 서비스를 데이터와 같은 위치에 배포하거나
    - 데이터 스토어에서 로직을 실행하는 것
    - 서비스를 데이터 스토어와 같은 노드 혹은 같은 리전에 배치해서 네트워크 대역폭 소비를 최소화할 수도 있음
    - <img width="414" height="302" alt="Screenshot 2025-10-23 at 8 07 01 PM" src="https://github.com/user-attachments/assets/37763633-6b29-4762-9e4b-4d2b1fe835b4" />
- 실행 코드를 데이터 스토어 프로시저로 만들어서 실행할 수도 있음
    - (비즈니스 로직을 저장 프로시저로 전환하는 셈)
    - 실행 코드와 데이터를 묶어서 지연 시간을 줄이고, 네트워크로 연결된 분산 클라우드 환경에서 효율적으로 애플리케이션을 동작할 수 있게 함
- 읽기 지연 시간이 감소
    - 하나 이상의 데이터 스토어로부터 데이터를 읽어와 정렬, 조인 연산을 할 때 패턴 사용
    - 데이터 aggregation이나 필터링 작업을 위해 여러 데이터 원천에서 데이터를 가져와야할 때 사용
- 데이터 노드의 CPU 자원 사용도 최대화할 수 있음
    - 데이터 노드는 I/O 작업에 치중하는 경향이 있어 나머지 CPU 자원은 유휴 상태일 것이라, 실행 코드를 데이터 노드에서 실행하면 리소스를 효율적으로 쓸 수 있음
    - 다만 질의 결과가 입력 데이터 크기와 차이가 거의 없는 경우는 메리트가 없다
    - 또한 데이터 스토어가 질의 마이크로서비스에서 전용으로 사용하는 경우에만 실행 코드를 데이터 스토어에 옮겨야함
        - 공유 데이터베이스에 프로시저를 실행하는건 성능이나 관리 측면에서 문제가 있기 때문/

**캐싱 패턴** 

- 이전에 조회한 데이터를 메모리에 저장하고 비슷한 질의가 들어오면 해당 데이터를 사용하는 방식
- cahce hit, miss
    - read-through cache : 캐시미스 발생 시 데이터 스토어에서 읽어와서 저장하는 방식
    - write-through cache : 데이터 변경 시 데이터 스토어에 내용을 반영하고 캐시에 저장된 데이터는 삭제하는 방식
    - cache invalidation (캐시 무효화)
- 데이터 캐시는 로컬 캐시로 인스턴스에 대한 데이터를 저장하거나, 여러 인스턴스의 데이터를 저장하는 것도 가능함
- 캐시는 사용 가능한 메모리를 소진할 수 있어 새로운 데이터를 캐시에 저장하려면 삭제 정책이 필요함
    - LRU : 가장 오래 사용하지 않은 데이터부터 삭제
    - FIFO : 가장 예전에 저장한 캐시부터 삭제
    - MRU : 가장 최근에 사용한 데이터부터 삭제
    - 발생한 이벤트 값에 따라 캐시 데이터를 삭제..등
- 각 캐시 데이터 별로 유효시간을 지정해서 시간이 지나면 삭제하고 다시 갱신함 → 데이터 스토어 간 일관성을 유지하기 위함.
- 이 캐시 패턴은 하나 이상의 클라이언트가 반복적으로 동일한 질의를 할 경우 캐싱해두면 좋다.
    - 데이터 조회시간이 단축
    - 정적 콘텐츠를 가져오는 시간도 단축된다. (거의 변경되지 않는 데이터를 제공할 때)
    - 데이터 스토어 경합 감소 (동시에 많은 요청을 처리하거나 경합이 발생하는 경우 캐시를 두어 데이터 스토어의 부담을 덜 수 있음)
    - 가용성이 일관성보다 더 중요한 경우, 캐싱을 통해 고가용성을 구현할 수 있음(DB가 잘 동작하지 않을 때 캐시 데이터를 내려서 처리)
    - 로컬 캐시나 공유 캐시가 필요한 모든 데이터를 저장할 수 없는 경우 분산 캐싱 시스템을 사용하기도 함
        - 분산 캐시를 구성하는 노드가 모두 같은 네트워크 내에 존재해야함
        - 클라이언트가 지리적으로 분산되어있으면 분산 캐시로 가까운 곳에 데이터를 저장하여 빠르게 응답할 수도 있다.

- 캐시 데이터는 캐시를 사용할 수 없는 경우에도 애플리케이션이 제대로 동작하도록 고려해야함. 메모리에 저장하는 것이기 때문에 데이터가 언제든지 사라질 수 있으며, 영구히 저장하는 원천은 DB여야함
- 데이터가 흘러넘칠 때(캐시가 저장할 수 있는 용량을 초과하여 메모리에 저장할 수 없을 때) eviction하기보다 로컬 캐시가 이 데이터를 디스크에 저장하는 방식으로 대응할수도 있음. 원천보다 디스크에서 읽어오는 것이 더 빠를 때 사용
    - 어떤 경우에 DB보다 디스크에서 읽어오는게 빠를까? (tmp 파일이라던지)

- 캐시 데이터의 문제점은 서비스를 확장할 때 각 서비스가 자신만의 로컬캐시를 가지고, 서로 다른 시점에 데이터스토어와 캐시를 동기화한다는 것
    - 각 마이크로서비스 캐시 데이터 간 데이터가 불일치하고 서로 다른 값을 반환할 수도 있음
        - 다른 서비스는 캐시가 무효화된 것을 알기 어려움
        - pub-sub 구조나 이벤트 소싱 패턴으로 캐시 무효화 정보를 전달하여 해소

cache invalidate API 

- 또한 캐시를 도입할 때 캐시 히트 비율, CPU, 메모리 사용량을 체크하여야함
    - 히트율이 낮다면 캐시 크기를 키우거나, 유효시간을 늘리거나, 캐시에 데이터를 미리 가져와서 저장하는 방식 등을 활용
    - 캐시에 대한 배치 업데이트를 수행하는 것이 좋음 (대역폭 사용과 성능 최적화 측면)
        - 캐시 업데이트 전에 동시에 쓰인적 있는지 체크하는 낙관적 방식
        - 전체 업데이트 시간 동안 잠금을 걸어서 변경을 막는 비관적 방식이 있음
- 캐시를 강제로 만료하거나 데이터를 다시 생성할 수 있도록 기능을 만들어두는 것이 좋음
    - 클라이언트에서 요청하여 변경 가능하도록
    - 웹 클라이언트가 브라우저 캐시를 초기화할 때 등

**정적 콘텐츠 호스팅 패턴**

- 데이터 스토어의 정적 콘텐츠를 클라이언트 가까운 곳에 배포하여 낮은 지연시간으로 제공하는 방법
    - CDN 과 같은 정적 콘텐츠 스토리지에 html, css, 이미지, 다운로드 파일 등의 정적 콘텐츠를 보관
    - 랜더링 서비스 부하를 줄일때도 사용
    - CloudFront
    - cloudflare (client side 구현 등등…)
- 정적 콘텐츠는 잘 변하지 않아서 이 패턴으로 지리/환경적으로 여러 곳에 복제하고 캐시에 저장해 배포하는 방식
- 클라이언트에게 정적+동적 데이터를 모두 보내야한다면, CDN이나 S3 버킷같은 스토어로 옮겨서 직접 정적 데이터를 조회하도록 구성할 수 있음
    - 동적 데이터를 CDN에서 다루는 케이스?

---

### 신뢰성 패턴

데이터 손실을 방지하기 위해 트랜잭션 신뢰성 패턴을 통해 데이터 저장 및 처리 방법을 알아보자.

**트랜잭션 패턴**

- 여러 작업을 묶어 하나의 큰 작업으로 실행하며, 전체가 실행되거나 실패되도록 함 (atomic)
    - 트랜잭션이 시작되면
    - 여러 데이터 변경 작업을 수행하고
    - 트랜잭션 종료 시 변경 내역을 커밋
    - 오류가 없다면 커밋이 성공하며 트랜잭션도 종료. 오류가 있다면 모든 작업을 복구하고 실패처리.
- 원자성, 일관성, 고립성, 지속성

Transactional isolation level

- **READ UNCOMMITED** : 커밋되지 않은 변경사항도 다른 트랜잭션이 읽을 수 있다
    - 더티체킹 (더티리드), 팬텀리드, non-repeatableread (이미 롤백됐거나 업데이트 전 데이터를 읽거나)
- **READ_COMMITED** : 커밋된 데이터만 읽는다. select 마다 최신 데이터를 갖고온다.
    - 쿼리마다 결과가 달라질 수 있고, 여전히 팬텀리드는 가능하다.
- **REPEATABLE_READ : 한 트랜잭션 내에서는 항상 같은 결과를 반환한다.**
    - 동일 행 읽기 일관성(은행 계좌 잔액 조회 등)
    - 하지만 팬텀리드(새로운 행이 삽입되면 범위 조회 결과가 달라질 수 있는)는 여전히 존재
- **SERIALIZABLE** : 가장 강력한 격리 수준이지만 처리량이 엄청 떨어짐. (금융거래 외에는 …)
    - 트랜잭션 쓰는 동안 병렬 읽기/쓰기 처리를 차단함
    - 트랜잭션 범위에 해당하는 데이터 변경 또한 차단

- 트랜잭션은 데이터베이스나 이벤트 스트림, 질의 시스템 등 여러 시스템 간 작업이 이루어질 수 있으며
    - 하나의 트랜잭션이 여러 시스템에 걸쳐 이루어지는 경우 XA, Paxos, Raft와 같은 알고리즘으로 처리함

- 작업이 단일 단계이거나 중간에 실패해도 문제가 없는 경우는 트랜잭션 패턴을 피해야함
- 또한 작업이 멱등성을 가지도록 해야함 (같은 작업을 여러 번 실행해도 결과가 같기 때문)
- 사가 패턴

---

### 볼트 키 패턴

데이터 스토어에 접근하는 것을 제어하고 보안 정책을 강제하는 방법

- 클라이언트가 제출하는 신뢰할 수 있는 토큰 기반
- 데이터 스토어에서 검증함
- 토큰 요청 → 볼트 키 생성 → 유효 시간 동안 클라이언트는 데이터 스토어에 접근 가능
- ID 제공자에 대한 인증서를 데이터 스토어가 보관하여 클라이언트는 직접 접근하지 않아도 복호화하고 인증할 수 있음 (토큰 검증을 위한 중간단계가 사라져서 지연시간을 줄일 수 있음)
    - 다만 클라이언트가 접근 권한을 얻으면 애플리케이션은 이후의 접근은 제어할 수 없음
    - 데이터 스토어가 키를 검증할 수 있는 경우에만 패턴을 사용할 것
    - 데이터 스토어가 키 기반의 접근 권한을 검증할 수 없다면 API 보안 기능으로 서비스를 두는 것도 좋음

### 데이터 관리 패턴 구현

애플리케이션이 어떤 데이터를 저장하고, 사이즈는 어느 정도이며, 기대하는 읽기 및 쓰기 성능은 어느정도인지, 시스템 일관성도 고려해야함

**관계형 데이터베이스**

- MySQL, 오라클, Postgres, H2
    - 관리형 RDBMS : RDS, 구글 클라우드 SQL 등
    - RDBMS를 확장하려면 master-replica 형태로 배포하거나 샤딩하는 방법
- 아파치 카산드라
    - 분산 NoSQL 데이터베이스, 컬럼 스토어
    - zero-downtime과 높은 성능을 제공
    - 데이터 센터나 리전 간 데이터 복제도 지원
    - 페타바이트 단위의 데이터를 다루며, 초 당 동시 수천 개의 작업을 처리
    - 약한 일관성을 제공하며, 쓰기 성능이 훨씬 좋음
    - 아마존 keyspaces
- 아파치 HBase
    - 확장 가능한 분산 NoSQL 컬럼 스토어, HDPS에서 동작하여 맵리듀스 작업 처리도 가능
    - 하둡 데이터에 대한 실시간, 랜덤 읽기/쓰기 접근 제공
    - 아주 큰 데이터 셋에 대한 선형적인 확장성을 제공하며 다른 구조의 스키마 데이터 원천을 쉽게 조합할 수 있다는 장점
    - 마스터-워커 배포를 사용하므로 SPOF. 일관성을 중요시한다면 HBase이나 고가용성을 중요시한다면 카산드라
    - 데이터가 너무 자주 삭제되거나 변경되는 경우 사용이 어려움
- mongoDB
    - json과 같은 도큐먼트 형태의 데이터를 저장할 수 있는 도큐먼트 스토어
    - 도큐먼트 구조나 정렬, 필터링을 바꾸지 않고도 필드를 추가하거나 삭제할 수 있음
    - 색인 / 데이터 일관성을 더 중요시함
    - mongoDB의 가용성은 주 스토어가 사용 불가능하면 읽기/쓰기 작업이 10~40초가량 중단되고 복제 스토어 중 하나가 선출되는 구조
    - 모바일 애플리케이션이나 컨텐츠 관리, 실시간 분석 등에 사용됨
    - 뚜렷한 스키마가 없으며 데이터 스토어 일부를 사용하지 않아도 문제가 없을 때 사용
- Redis
    - 인메모리 key-value 스토어로 캐시를 저장할 때 많이 사용
    - 문자열 키와 더불어 목록, 집합, sorted 집합, 해시, 비트 배열 등 다양한 타입을 저장할 수 있음
    - LRU에 따른 key-value 삭제, 자동 복구, 디스크 저장 기능 등을 지원함
    - Redis Database Backup과 Append Only File 두가지 형태로 데이터를 영구 저장 가능하기도 함
    - CQRS 패턴처럼 단일 마스터 노드와 여러개 복제노드로 고가용성을 제공하고, 데이터 샤딩도 지원
    - 하지만 복잡한 데이터 처리, 데이터 aggregate와 같은 기능은 없어서 nosql을 대체할 수는 없음
- DynamoDB
    - key-value 및 도큐먼트 데이터베이스로 낮은 지연시간과 높은 확장성을 제공함
    - 하루에 수십 조 개의 요청, 초 당 2천만개 이상의 요청을 처리할 수 있다.
    - SSD에 데이터를 저장하고 자동으로 파티션을 나누어 처리한 다음 mutli AZ에 복제됨
    - 테이블 조인이나 외래키 기능이 없어서 질의에는 제약이 있음
- 아파치 HDFS
    - **분산 파일시스템**으로 저렴한 하드웨어에서 실행해도 최소 3개의 복제본을 분산저장하여 데이터 탄력성이 높음
        - HDFS에 저장된 데이터는 변경이 불가능 (append-only에 적합)
        - 데이터 스트림 방식으로 읽고 쓰는데 최적화
        - 하둡 맵리듀스 작업에서 대용량 데이터를 효과적으로 처리하기 위한 데이터 소스로 주로 활용
    - 데이터를 여러 데이터 노드에 저장해서 데이터에 대한 모든 메타 데이터를 단일 네임노드 메모리에 저장함
        - 해당 노드에서 장애가 발생하면 읽기쓰기가 불가능, 파일 수가 제한되어있다
        - 순차 읽기에 최적화
- S3
    - 오브젝트 스토리지로, data lake나 데이터 백업, 아카이브, 빅데이터 분석 등에 사용됨
        - 아테나와 표준 SQL 구문을 통해 분석 작업도 지원
        - s3 select를 통해 오브젝트 데이터 일부를 읽을 수 도 있다.
        - 높은 가용성과 세밀한 데이터 접근도 제공함
        - s3 버킷 리전 이전도 지원함
        - 유스케이스에 따른 스토리지 타입을 선택할 수 있음
    ```
    Standard IA: 자주 access하진 않는데 필요하면 즉시 액세스해야함. (이 클래스로 전환되려면 최소 30일)
    one_zone IA : 한 군데의 AZ에만 저장됨 (최소 30일)
    Intelligent tiering : 액세스 빈도가 불규칙해서 잘 모를 때
    S3 Glacier Instant Retrieval(IR) : 거의 액세스는 안하는데 ms 단위로 검색은 되어야함
    S3 Glacier Flexible Retrieval(FR) : 검색보다는 저장 주용도. 검색하려면 3~5시간 걸림 (최소 스토리지 90일)
    Deep Archive : 10년 이상 저장할 데이터 (최소 스토리지 기간 180일)
    ```

- 애저 코스모스DB
    - 완전 관리형 NoSQL 데이터 스토어
    - 멀티 모델 아키텍처를 통해서 단일 스토리지 엔진 위에 API 모델을 여럿 제공함 => key-value, 도큐먼트, 컬럼, 그래프 데이터베이스로도 사용 가능
    - 글로벌 분산 기능(리전 간 자동 복제) 제공,여러 리전에 동시 쓰기 가능
    - RDB처럼 일관성 모델을 갖고 있다(5 level)
        - 완전 동기, 지정된 시간 지연 허용, 세션 단위로 일관성 유지, 순서만 보장, 완전 비동기 복제
    - 다만 request Unit 별로 과금이 발생해서 읽기/쓰기 설계를 잘해야함

- 구글 클라우드 스패너
    - 완전 관리형 관계형 데이터베이스
    - 무한한 크기 확장과 강력한 일관성을 제공
    - SQL 질의 처리, 모든 노드에서 트랜잭션을 지원함
    - 읽기 쓰기 트랜잭션을 선형적으로 확장 가능하며 데이터 계층의 암호화, 접근제어를 통한 보안 제공도 함

---

### 테스팅

- 데이터 서비스와 스토어 간의 테스트
    - 코드와 작업 간 데이터 일관성이 유지되는지
    - 데이터 스토어 타입과 버전을 테스트해서 예외상황을 확인해야함
    - 데이터 매핑 테스트
    - 관계 제약, 트리거, 저장 프로시저가 정상적으로 동작하는지
    - 부하 테스트 (락, 일관성, 성능 병목 등을 확인 가능)

### 보안

- 권한이 있는 사람과 시스템만 데이터에 접근 가능하도록
- 볼트 키나 API 보안 등을 통한 데이터 접근, 암호화하여 저장
- 민감한 데이터는 추가 보안 정책을 적용하고 마스킹 처리

### 관측 가능성 및 모니터링

클라우드 네이티브 애플리케이션의 지표나 로그, 분산 추적 결과

- 애플리케이션 메트릭
    - 데이터 스토어 가동시간과 상태
    - 질의 처리시간
        - 비효율적인 질의
        - 데이터 스토어 데이터 증가
        - 동시성
        - CPU, 메모리, 디스크 공간 등 리소스 부족
        - 의존 시스템 또는 복제본 사용이 불가능한 경우
- 시스템 지표
    - CPU 점유율, 메모리 사용량, 사용 가능한 디스크 공간, 네트워크 사용량, 디스크 I/O 등
- 데이터 스토어 로그
- 주 - 복제 데이터 스토어 간 통신에 소요되는 시간, 처리량
- 엘라스틱 서치나 키바나같은 데이터 스토어 로그 분석툴로 쿼리가 실패한 원인을 알려줌

데브옵스

- 데이터 스토어 유형
- 배포 패턴
- 데이터 보호 정책
- 모니터링 설정 및 관측 가능성
- 자동화된 지속적 전달
