```toc
```

## 4.1 데이터 아키텍처

![](files/Pasted%20image%2020250928160727.png)

- data source
	- 사용자 입력, 센서 측정값 등 데이터를 입력하는 곳
	- data ingestion system에 데이터를 입력하거나, 데이터 스토어로 직접 데이터를 입력할 수도 있음
	- data ingestion system은 데이터를 이벤트나 메시지 형태로 다른 애플리케이션이나 데이터 스토어로 전달함
	- 이를 통해 신뢰할 수 있는 비동기 데이터 처리 기법을 구현할 수 있음
- data store
	- 데이터 아키텍처의 핵심
	- 다양한 형태의 데이터를 저장, 경우에 따라 공간을 확장
	- 이를 기반으로 보고서를 만들거나, 데이터 관련 API를 제공
- real-time/stream-processing system
	- 이벤트를 그때그때 처리해서 유용한 결과를 만들거나 경고, 알림 등을 제공
- batch processing system
	- 배치로 데이터를 제공받아 이를 처리하고, 그 결과를 데이터 스토어에 저장
	- 이는 다시 보고서로 제공되거나 API로 외부에 제공
	- 파일 시스템과 같이 다른 데이터 스토어에서 데이터를 읽어서 처리하고, 이를 관계형 DB처럼 다른 데이터스토어에 또 저장할 수도 있다

- 클라우드 네이티브 마이크로서비스는 크기 조절이 자유롭고, 탄력적이며 관리가 쉽다.
- 클라우드 네이티브 데이터들도 전통적인 데이터 처리 분야랑 좀 다르다
- 가장 중요한 특징은 데이터 포맷이 서로 다르거나, 다양한 형태의 데이터 스토어가 존재
- 고정된 스키마를 가지지 않고, 가용성, 성능 등의 이유로 여러 곳에 중복해서 존재하는 게 좋다
- 또한 여러 클라우드 네이티브 서비스가 같은 데이터베이스를 사용하지 않고 대신 각 서비스 고유의 데이터 스토어를 가지도록 하고, 외부에서 데이터에 접근할 수 있도록 API 제공
- 이런 데이터 분리 덕분에 크기를 쉽게 확장 가능

## 4.2 데이터 타입과 형태
- 애플리케이션은 크게 3가지 주요 데이터 타입에 큰 영향을 받음
	- 입력 데이터
		- 사용자 또는 클라이언트가 주는 데이터 
		- JSON, XML, gRPC, Thrift 등
	- 설정 데이터
		- 환경 등과 관련된 값을 변수 형태로 전달
		- 최근에 YAML 많이 씀
	- 상태 데이터
		- 애플리케이션 자체가 현재 메시지나 이벤트에 기반한 상태를 기록하고, 저장
		- 현재 상태를 저장하고, 시작 시에 읽어올 수 있다면 애플리케이션이 재시작해도 이전에 처리하던 작업을 끊김없이 계속 진행할 수 있다

- 애플리케이션이 오로지 입력, 설정 데이터에만 영향을 받으면 이를 Stateless Application이라고 한다.
- 이는 구현이 쉽고, 언제든지 재시작 가능해서 확장이 쉽다

- 반면에 상태도 필요로 하는 애플리케이션을 Stateful Application이라고 한다
- 이는 상대적으로 구현이 어렵다.
- 상태를 반드시 저장해야 하고, 관리해야 재시작해도 문제없이 실행을 재개할 수 있다.

- 데이터 형태는 크게 3가지
	- 정형 데이터 
		- 미리 정의한 스키마에 잘 맞는 데이터
	- 반정형 데이터
		- 데이터가 일부 구조적 형태
		- 데이터가 참조를 위한 키, 이름을 가지고는 있지만 모든 데이터가 형태가 같다고 보장할 수는 없음 
		- JSON, YAML 등 
	- 비정형 데이터
		- 참조 등을 위한 의미 있는 필드가 전혀 없다
		- 이미지, 비디오, 저수준 텍스트 콘텐츠 등

## 4.3 데이터 스토어
- 데이터에 따라 적합한 데이터 스토어를 사용해야 한다
- 정형, 반정형, 비정형 데이터에 따라, 그리고 확장성과 가용성 요구사항에 따라 적절한 데이터 스토어를 선택

### 4.3.1 관계형 데이터베이스
- 미리 정의한 스키마에 따라 정형 데이터를 저장
- SQL을 사용
- 데이터를 쓰기 전에 스키마를 정의해야 하는 Schema on Write 정책을 따르기도 한다.

- 인덱스, 정규화를 통해 읽기 및 쓰기 최적화
- ACID 지원해 트랜잭션 보장

- 관계형 데이터베이스는 반정형 데이터에는 잘 맞지 않는다.
- 다만, 데이터를 관계형 데이터베이스, NoSQL에 분리해서 저장하면 가져오는 데 부담이 커지므로 비정형 혹은 반정형 데이터를 blob이나 TEXT 형태로 저장하기도 한다.

- 클라우드 네이티브 애플리케이션 데이터 저장에도 좋은 선택지
- 각 MS가 별도의 관계형 데이터베이스를 사용하면 확장성도 좋고, MS와 DB를 단일 단위로 묶어서 배포하기도 좋다.
- 단, 설계부터 확장성이 떨어지긴 한다.
- primary, secondary 구조만 지원하고 여러 노드 중 단 하나에만 쓰기가 가능

- 따라서 저장하는 레코드 수가 데이터베이스가 효과적으로 처리할 수 있는 수를 넘지 않을 때 사용하는 게 좋다
- 고객 주문, 로그, 알림 등 데이터 크기가 계속 증가할 것으로 예상되는 경우 관계형 데이터베이스를 데이터 확장 패턴을 통해 배포하거나 다른 데이터 스토어를 쓰는 게 좋다.

### 4.3.2 NoSQL 데이터베이스
- not Only SQL로 이해하는 게 좋다.
- schema on read 정책을 따른다
	- 데이터를 읽을 때 스키마를 정의
	- 데이터를 쓸 때는 스키마를 정의할 필요가 없다
- 따라서 확장성과 성능이 중요한 빅데이터 처리에 많이 쓴다

- 기본적으로 데이터를 분산 저장하므로, 여러 클라우드 네이티브 애플리케이션에 쓸 수 있다.
- 성능 최적화를 위해 NoSQL DB는 보통 데이터를 정규화하지 않고, 중복 필드를 가지기도 한다.
- 데이터를 정규화하면 데이터를 가져올 때 여러 테이블 조인 등이 필요한데 분산 저장이라는 NoSQL 특성 때문에 성능이 떨어진다

- 성능 및 확장성 문제로 인해 소수의 NoSQL DB만 트랜잭션을 지원

- 관계형 DB와 달리 NoSQL DB는 제각각 동작 방법이 다르다
- 일관성, 가용성 제공 방식에 따라 아래와 같이 분류 가능

- key-value store
	- 레코드를 키-값 쌍으로 저장
	- 데이터 캐싱에 많이 사용
	- redis, Memcached, Ehcache
- column store
	- 각 행에 여러 column 값 쌍을 저장할 때 사용
	- schema on read 대표적
	- 데이터를 쓸 때는 몇 개의 컬럼이든 자유롭게 기록하고, 읽을 때는 원하는 컬럼만 명시
	- Apache Cassandra, HBase 등

![](files/Pasted%20image%2020250928173018.png)

- document store
	- JSON, XML 등 반정형 데이터 저장
	- 경로 표현식으로 저장된 데이터 처리도 가능
	- JSON, XML 덕분에 front랑 통신하는 API 분야에 많이 사용
	- MongoDB, CouchDB, CouchBase 등이 많이 쓰임
- graph store
	- 데이터를 node로 저장하고, edge를 통해 데이터 노드 간 관계를 표현
	- 저장하는 데이터는 다차원 형태, 소셜 미디어의 관계나 거래 네트워크 구축하고, 거래 사기를 탐지하는 등에 활용
	- Neo4j를 가장 많이 사용

- object store, time-series 등은 특정 목적을 가지고 사용하는 데이터를 저장하고 질의할 때 많이 쓴다
- 몇몇은 여러 분류에 포함되는 이른바 멀티 모델 형태로 동작하기도 한다
- DynamoDB는 key-value store이면서 document store이기도 한다.
- CosmosDB 등도 key-value store이자 document, graph store

- 기본적으로 분산 동작하므로 CAP 이론 적용 가능
- 모두 만족할 수는 없기에 NoSQL마다 선택이 다름

| 구분           | 일관성 우선                                     | 가용성 우선                |
|----------------|------------------------------------------------|----------------------------|
| 키-값 스토어   | 레디스, Memcached                              | 다이나모DB, Voldemort      |
| 컬럼 스토어    | 구글 클라우드 빅테이블, 아파치 HBase           | 아파치 카산드라            |
| 도큐먼트 스토어 | 몽고DB, 테라스토어                            | 카우치DB, 심플DB           |
| 그래프 스토어  | 애저 코스모스 DB                               | Neo4j                      |

- 경우에 따라서 일관성, 가용성 모두 제공하기도 함
- 카산드라는 일관성 수준을 ONE, QUORUM, ALL 수준으로 지정해서 사용

### 4.3.3 파일 시스템 스토리지
- 비정형 데이터를 쓸 수 있는 가장 좋은 방법
- NoSQL과 달리 데이터에 대한 이해가 필요가 없고, 데이터 읽기 및 쓰기 성능 최적화에 초점을 둔다
- 대용량 데이터 캐시로 사용하기도 함

- 가장 저렴하지만 텍스트나 반정형 데이터 저장하기에는 좋지 않을 수 있음
- 단일 데이터 검색에도 여러 파일을 읽어야하는 경우가 있기 때문
- 이런 경우 Solr나 Elasticsearch 등의 검색 시스템을 쓰는 게 좋다.

- 저장하는 데이터가 점점 증가하는 경우 분산 파일 시스템을 사용
- HDFS, S3, Azure Storage Service, Google Cloud Storage 등

### 4.3.4 데이터 스토어 정리
- 데이터가 연관성이 강하고, 트랜잭션을 보장해야 한다면 관계형 데이터 스토어 사용
- 반정형, 비정형 필드를 가지고 있다면 NoSQL이나 파일 시스템에 저장해 트랜잭션 보장하면서 확장성을 제공
- 데이터가 아주 크고, 질의 기능을 제공해야 한다거나 데이터가 반정형이거나 그래프 처리 같은 특수 기능이 필요하다면 NoSQL
- 콘텐츠 처리가 필요없다면 파일 시스템 스토어

## 4.4 데이터 관리

### 4.4.1 중앙 데이터 관리
![](files/Pasted%20image%2020250928182740.png)
- centralized data management 방식은 전통적인 데이터 중심 애플리케이션에서 자주 사용
- 모든 데이터를 단일 DB에 저장하고, 여러 컴포넌트가 단일 DB에 접근

 - 이는 테이블 정규화 가능, 아주 높은 데이터 일관성 제공
 - 여러 컴포넌트가 모든 DB 테이블에 접근이 가능해 중앙 데이터 스토어가 여러 테이블에 데이터를 빠르게 저장하고 가져올 수 있음
 - 그러나 DB와 애플리케이션 간 강한 연관성이 생기고, 애플리케이션을 독립적으로 개선하고 발전하기 어려워짐
 - 이런 특성 때문에 클라우드 네이티브 애플리케이션에서 피해야 할 패턴으로 여겨진다

### 4.4.2 분산 데이터 관리
- 각각을 독립적인 MS로 설계, MS가 각각 별도의 데이터 스토어 사용
- 이런 decentralized data management 방식은 각 마이크로서비스가 다른 마이크로서비스에 영향을 미치지 않고 크기 조절을 자유롭게 할 수 있음
- 이러면 DB와 애플리케이션 간 강한 연관성이 생기지 않고, 쉽게 애플리케이션을 바꿀 수 있음

- 데이터를 관리하거나 바꿀 여지가 많지 않지만 개발 팀이나 소유자가 별도로 나뉘어있는 경우 MS 별로 데이터를 분리하면 데이터 관리나 소유권 문제를 쉽게 해결할 수 있음
- 새로운 기능 구현, 릴리스 소요 시간 등을 단축 가능

![](files/Pasted%20image%2020250928183006.png)

- 이 방식을 쓰면 서비스별로 데이터에 더 적합한 데이터 스토어 사용 가능

### 4.4.3 하이브리드 데이터 관리
![](files/Pasted%20image%2020250928183121.png)
- 단일 데이터베이스를 사용하면 위 내용 말고도 여러 운영상의 장점이 있음
- 보안 정책 강제, 데이터 보호 법률 적용 등
- 분산 데이터 관리 방식의 단점 중 하나는 별도 데이터 스토어를 쓰는 데서 오는 비용 부담
- 따라서 크지 않은 조직은 hybrid data management 방식을 사용하기도 함
- 같은 팀이 서비스를 관리하고, 같은 바운디드 컨텍스트 내에 존재
- 단, 다른 서비스가 사용하는 테이블에 접근하지 않도록 주의
- 나중에 DB 분리하기가 힘들어짐
### 4.4.4 데이터 관리 정리
![](files/Pasted%20image%2020250928183143.png)
- 독립적인 데이터 스토어를 구축하고, 잘 정의된 API로 서로 통신

## 4.5 데이터 조합 패턴 
![](files/Pasted%20image%2020250928183216.png)
- MS는 데이터 스토어에 있는 데이터에 대한 소유권이 있음
![](files/Pasted%20image%2020250928183249.png)
- 서비스에 부하가 많이 생기면, 데이터 가져오는데 지연이 생기고, 캐시 등을 써서 지연 시간을 줄일 수 있음

![](files/Pasted%20image%2020250928183257.png)
- 더 복잡해지면 서비스들을 더 작은 마이크로서비스들로 나눈다
- 이 과정에서 여러 서비스가 같은 데이터를 공유하지 않도록 연관 데이터 역시 분리해서 새로운 서비스로 이동
- 데이터를 두 개의 데이터베이스로 나누는 것이 직관적이지 않을 수 있고, 경우에 따라서는 다른 방법을 사용해서 데이터를 안전하게, 재사용 가능한 방법으로 공유해야 할 수도 있다.

### 4.5.1 데이터 서비스 패턴
- data service pattern은 데이터를 서비스 형태로 제공하고, 이를 데이터 서비스라고 지칭
- 데이터 서비스가 데이터에 대한 소유권을 지님, 데이터 스토어에 데이터 추가하고 가져오는 책임을 가짐
- 간단한 조회를 하기도 하고, 응답을 위해 복잡한 작업을 하기도 함

#### 어떻게 동작할까요
- 서비스로 제공하면 더 많은 제어가 가능
- 다양한 조합으로 데이터 제공, 보안 적용, 정책 기반 자원 사용 제한 등
- 간단한 읽기 및 쓰기 작업, 여러 테이블 조인이나 store procedure 실행 등
- 캐시로 읽기 성능 향상 등

![](files/Pasted%20image%2020250928184936.png)

#### 어떻게 사용할 수 있나요
- 여러 MS가 데이터 접근할 때
	- 한 서비스가 데이터에 대한 소유권을 가지고, 다른 MS에서는 데이터 쓰기만 하기
- 레거시 혹은 전용 데이터스토어를 다른 서버에서 쓸 수 있도록 추상화
	- 레거시 DB가 있고 이걸 C# 드라이버로 접근할 수 있다면 다른 애플리케이션도 다 C#이어야 함
	- API로 하면 내부 구조, 기술 등을 전혀 신경쓰지 않고 작업 가능
	- DB를 나중에 교체하는 것도 가능

#### 고려해야 할 사항들
- 여러 서비스가 같은 데이터 접근하는 건 피해야 함
- 강한 연관성이 생기고, 각 MS가 독자적으로 발전하기 어렵게 만든다
- API로 연동하면 연관성을 조금 느슨하게 만들 수 있다.

- 특정 MS가 데이터와 분명한 연관성을 지니면 이 패턴을 사용해서는 안 된다.
- 불필요한 MS가 생기고, 추가적인 관리 부담이 생김
#### 관련 패턴들
- 캐싱 패턴
	- 로컬 또는 분산 캐싱으로 읽기 성능 최적화
- 성능 최적화 패턴
	- 조인 연산, store procedure 실행 등 복잡한 질의를 처리해 성능 향상
- 구체화된 뷰 패턴
	- 로컬 스토어에 중복 저장하고, materialized view 만들어서 성능 향상
- 볼트 키 패턴
	- API 보안 + audit 

### 4.5.2 조합 데이터 서비스 패턴
- composite data services pattern
- 하나 이상의 데이터 서비스로부터 데이터 읽어서 조합하고, 필요한 경우 더 복잡한 작업을 통해 명료한 데이터 제공
- 사용자가 아닌 서비스 쪽에서 데이터를 조합해서 server-side mashup pattern이라고 한다.

#### 어떻게 동작할까요
![](files/Pasted%20image%2020250930205059.png)
- 서비스 오케스트레이션과 비슷
- 여러 서비스와 자신의 데이터 스토어에서 데이터를 가져와 조합한 데이터를 제공
- 직접 데이터 조합 안 해도 됨 + 캐시로 성능 향상

#### 어떻게 사용할 수 있나요
- 비슷한 조합을 여러 곳에서 사용하면 한 곳에서 대신 해주면 편함
- 또한 클라 영향 없이 데이터 조합 로직을 바꾸는 것도 가능
- 캐시로 성능 향상도 가능

#### 고려해야 할 사항들
- 여러 MS가 조합하는 데이터가 비슷할 때만 사용
- 아니면 불필요한 서비스 계층만 생기고, 서비스 재사용하는 경우도 줄어든다
- 클라 복잡도를 줄이고, 데이터를 재사용하고, 서비스 계층을 추가함으로써 생기는 추가 지연 시간과 관리 복잡도를 비교해서 이득이 클 때만 사용
	- 흠 내부 서비스 찔러서 오히려 지연 시간 면에서는 이득을 볼 수 있지 않나요?

#### 관련 패턴들
- 캐싱 패턴
	- 캐시로 성능 최적화
	- 경우에 따라서는 뒷단 서비스가 죽은 경우에도 데이터 제공 가능
- 클라이언트 사이드 매시업 패턴
	- 클라 쪽에서 데이터를 조합할 수도 있음
	- 비동기 읽기가 가능하고, 부분 데이터 만으로 데이터 조합이 가능하면 좋은 선택이 될 수도 있음

### 4.5.3 클라이언트-사이드 매시업 패턴
- client-side mashup pattern
- 클라에서 여러 데이터 서비스를 찔러 조합
- 클라는 보통 웹 브라우저, 비동기 호출로 데이터 가져옴

#### 어떻게 동작할까요
![](files/Pasted%20image%2020250930205051.png)

- 비동기 데이터 로딩 사용
- 일부분을 화면에 표시하면서 동시에 데이터를 불러와 나머지를 표시
- 그때그때 표시하는 게 사용자 경험 측면에서 좋다
- 이를 RIA(Rich Internet Application)이라고도 부른다

#### 어떻게 사용할 수 있나요
- 중요한 데이터를 낮은 지연시간으로 보여주기
	- 중요 정보를 빠르게 불러오고
	- 나머지 자세한 정보를 동적으로 업데이트
- 웹 페이지를 훨씬 더 빨리 불러오는 듯한 효과
	- 일부만 먼저 보여줘도 훨씬 빠르게 로딩된 것 같은 착각

#### 고려해야 할 사항들
- 부분 데이터를 바로 보여줄 수 있거나, 일부 데이터를 의미있게 사용할 수 있는 경우에만 사용
- 전체 데이터를 조합하거나, 일부 데이터를 다른 데이터와 합쳐야만 하는 경우에는 사용하지 않기

#### 관련 패턴들
- 조합 데이터 서비스 패턴
	- 콘텐츠를 동기적으로 가져와 데이터를 조합하는 것이 자주, 여러 서비스에서 쓰인다면 좋다
- 캐싱 패턴
	- 지연 속도 개선

### 4.5.4 데이터 조합 패턴 정리

|패턴|사용해야 할 경우|사용하면 안되는 경우|이점|
|---|---|---|---|
|**데이터 서비스**|• 단일 서비스가 데이터를 소유하지 않으며, 여러 마이크로서비스가 데이터에 의존하는 경우|• 데이터가 본질적으로 특정 서비스에 귀속되는 경우, 불필요한 마이크로서비스를 추가하게 되면 관리 복잡도만 증가함|• 서비스 간 결합도를 낮춤<br>• 공유 데이터에 대한 작업을 더 잘, 그리고 안전하게 처리할 수 있음|
|**조합 데이터 서비스**|• 많은 클라이언트가 필요한 데이터를 얻기 위해서 여러 서비스에 질의를 보내는 경우, 그리고 이런 데이터를 여러 클라이언트가 공통으로 사용하고 재사용이 가능한 경우|• 하나 또는 소수의 클라이언트에서만 사용하는 데이터의 경우<br>• 클라이언트에서 데이터를 조합하는 방법을 일반화하여 다른 클라이언트에서 재사용이 불가능한 경우|• 데이터를 얻기 위한 클라이언트 측의 중복 작업을 줄여주고 이를 공통 서비스로 제공<br>• 캐시나 정적 데이터 등을 통해 데이터를 더 탄력적으로 제공할 수 있음|
|**클라이언트 사이드 매시업**|• 일부 데이터 만으로도 의미 있는 작업이 가능한 경우, 예를 들어 웹 브라우저에서 다른 데이터에 종속적이지 않은 데이터만 별도로 표시하는 경우|• 별도로 가져온 데이터들을 합치거나 조합하는 등 별도의 처리과정을 거쳐야만 의미 있는 작업이 가능한 경우|• 좀 더 응답이 빠른 애플리케이션을 만들 수 있음<br>• 사용자 대기 시간을 줄일 수 있음|

## 4.6 데이터 확장 패턴
- 부하 증가하면 서비스나 데이터 스토어가 병목
- 빅데이터라면 NoSQL이나 분산 파일 시스템
- 이는 데이터 확장, 분할 등을 쉽게 할 수 있게 해줌

- 단, 데이터 일관성이나 트랜잭션 같은 요구사항이 있다면 관계형 데이터베이스 사용
- 이는 확장성이 고려되지 않음
- 따라서 이는 구조를 변경하여 확장성을 구현

### 4.6.1 데이터 샤딩 패턴 
- 데이터를 샤드로 나누어서 데이터 저장 및 읽기 규모를 자유롭게 조절
- 데이터를 하나 또는 여러 속성에 따라서 분할

#### 어떻게 동작할까요
- 수평, 수직, 기능적 샤드

- 수평적 데이터 샤딩
![](files/Pasted%20image%2020250930205455.png)
- 각 샤드는 같은 스키마를 사용, 샤딩 키에 따라 서로 다른 데이터 레코드를 지님
- 데이터베이스 테이블은 각 샤딩 키에 따라서 여러 노드에 나뉨
- 주문 ID에 따라 세 개의 샤드로 나뉨


- 수직적 데이터 샤딩
![](files/Pasted%20image%2020250930205813.png)
- 같은 스키마를 사용하지 않고, 서로 다른 데이터 필드를 가질 수 있음
- 각 샤드는 다른 샤드에 있을 필요가 없는 테이블 데이터 일부를 가진다
- 데이터 접근 빈도에 따라서 데이터를 나눌 때 좋다.

- 기능적 데이터 샤딩
![](files/Pasted%20image%2020250930205849.png)
- 사용 목적이나 기능에 따라 나눌 수도 있다.

- 수직적, 기능적 데이터 샤딩은 기능 분리에 한계가 있다.
- 결국 데이터 더 확장하기 위해서는 수평적 데이터 샤딩을 사용할 수밖에 없는 시점이 온다.
- 수평적 데이터 샤딩을 할 때는 다음 방법으로 어디에 데이터를 저장할지 결정한다.

- 디렉토리 기반 샤딩
	- 검색 서비스, 분산 캐시를 통해서 샤드 키와 실제 데이터의 위치 간 정보를 저장
	- 데이터를 가져올 때 샤드 키로 위치를 찾고, 거기서 데이터를 가져옴
	- 데이터가 재배치되는 경우 클라는 변경된 위치를 찾기 위해 다시 샤드 키로 정확한 위치를 검색해야 함
- 범위 기반 데이터 샤딩
	- 샤딩 키가 연속적이라면 쓰기 좋음
	- 범위로 나누어서 샤딩
	- 날짜나 시간에 따라 데이터를 나누고 저장할 때 좋음
- 해시 기반 데이터 샤딩
	- 데이터 필드를 샤드 키로 쓰거나, 날짜 범위로 데이터를 나누면 균등하지는 않음
	- 조금 더 균등한 걸 원한다면 해시 데이터 기반 샤딩을 할 수 있음
	- 샤드 키로 해시 값을 만들고, 이걸로 위치를 결정
	- 데이터의 범위 단위로 질의하는 경우 잘 맞지 않지만 개별 데이터 질의에는 좋다
	- 검색 서비스와 함께 써서 해시 값과 그에 대한 샤드 위치를 저장하는 방법을 쓰기도 함

- 샤딩을 제대로 쓰려면 고유 데이터를 식별할 수 있는 하나 이상의 데이터 필드가 있거나, 데이터를 의미있는 하위 그룹으로 나눌 수 있는 데이터 필드가 필요
- 샤드 키와 관련된 데이터 필드 값은 고정되어 데이터가 변해도 해당 값은 절대 변하지 않아야 한다
- 데이터 필드 값이 바뀌면 샤드 키가 바뀌어서 데이터를 재배치해야한다.
	- 피하는 게 좋다

#### 어떻게 사용할 수 있나요
- 데이터를 싱글 노드에 저장하지 않거나, 데이터를 분산해 지연 시간을 낮출 때

- 싱글 노드에서 멀티 노드로 확장
	- 스토리지, 연산, 네트워크 대역폭 등이 병목일 때 데이터 샤딩을 사용
	- 수평 확장이 가능해짐
- 데이터 조회 시간 단축을 위한 데이터 분리
	- 여러 필드를 조합해 샤드 키를 만들고, 데이터를 분리
	- A, B로 샤드 키를 만들면 두 값으로 위치를 찾아서 빠르게 조회 가능
	- 만약 A, C만 알면 샤드를 찾을 수 없음 -> 계층적 샤드 키를 사용
	- A에 해당하는 샤드를 모두 찾고, 거기서 C로 검색 -> 검색하는 샤드 수를 줄일 수 있음
	- 혹은 A, C로 부 샤드키를 만들고 색인을 관리하기도
	- 단, 데이터를 변경할 때 부 샤드키도 변경해야 하므로 데이터 수정 비용이 커짐
	- 혹은 날짜나 시간 범위로 데이터를 나눌 수 있음.
	- 최근 데이터를 핫 샤드에 저장하고, 나머지 주문들을 아카이브 샤드에 저장
		- 대신 주기적으로 데이터 이동이 필요함
- 지리적 데이터 분산
	- 클라가 지역 별로 분산된 경우 지역에 따라 데이터를 나누고, 가까운 데이터를 지역별로 모을 수 있다
	- 이렇게 하면 요청에 대한 응답 시간이 빨라짐 
	- 단, 전 세계를 대상으로 데이터를 조합해야 한다면 모든 샤드를 조회해야 함
		- 이 경우 가장 빠르게 응답한 첫 데이터 먼저 보내주고 이후 나머지 데이터를 조합한다거나 등
		- 혹은 전체 데이터를 잘 캐싱하거나

#### 고려해야 할 사항들
- 샤드 데이터 양을 최대한 비슷하게 만들어서 부하가 고르게 분산되도록
- 부하가 균등하지 않으면 데이터 재배치 필요
- 데이터 변경으로 샤드 불균형은 언제든지 발생할 수 있음

- 이런 재배치 작업을 효율적으로 하려면 샤드 크기를 가급적 작게 유지
- 장기적으로 뛰어난 확장성, 전체 시스템 영향 적게 데이터 재배치 빠르게 가능

- 장애 상황 대비 여러 개의 샤드 복사본 유지하면 좋다
- 가용성도 높아지고, 전체 시스템 중단 없이 유지보수 작업 가능해짐

- 여러 샤드 간 데이터 aggregation 처리는 종류별로 다르다
- 평균, 최소, 최대 등은 각 샤드에서 처리한 데이터를 합쳐서 계산 가능
- 그러나 중앙값 등은 모든 데이터가 필요해 샤딩으로 구현이 어렵다.

- 샤드 키를 만들 때 자동 증가 필드는 쓰지 않는 게 좋다.
- 각 샤드가 서로 통신하지 않으므로 중복이 발생할 수 있음
	- 데이터 재분배시 귀찮아짐

- 샤드 키는 최대한 균등 배분 가능한 값을 선택

#### 관련 패턴들
- 구체화 된 뷰 패턴
	- 각 샤드의 종속 데이터를 서비스의 로컬 스토어에 복제해 성능 향상, 데이터 스토어 호출 횟수 줄이기
	- 단, 약한 일관성을 지니므로 일관성이 그렇게 중요하지 않을 때 사용
- 데이터 지역성 패턴
	- 서로 연관이 있는 데이터들을 샤드에 모아 색인을 만들고, 더 효과적인 조회를 위해 store procedure 실행

### 4.6.2 명령과 조회 책임 분리 패턴
- CQRS는 변경과 질의를 분리하고, 각각의 동작이 서로 다른 데이터 스토어를 다루도록 해 데이터 변경과 조회를 더 빠르게 처리 
- 데이터를 더 다양하게 다룰 수 있게 해주고, 높은 확장성과 보안성
- 변경 및 질의 모델을 독립적으로 변경 가능, 각 모델에 영향을 거의 미치지 않음

#### 어떻게 동작할까요
![](files/Pasted%20image%2020250930211050.png)
- 변경과 조회를 별도의 서비스로 나눔
- 각 서비스가 변경과 읽기를 서로 다른 노드에서 수행
- 덕분에 쉽게 모델링하고 서비스들이 독립적으로 크기 확장 가능

- 명령과 질의에서는 데이터 스토어에 특화된 정보를 제공하면 안 된다. 애플리케이션과 관련된 데이터를 다루어야 한다.
- 서비스에 명령을 전달하면 메시지를 해석해서 데이터 스토어를 변경
- 이는 비동기로 질의 서비스로 전달되어 데이터를 저장
	- 카프카와 같은 로그 기반 큐 시스템. 이벤트 소싱 패턴
- 질의 서비스는 이벤트 큐에서 데이터를 읽고, 데이터 질의에 최적화된 패턴으로 로컬 스토어에 데이터를 변경 
#### 어떻게 사용할 수 있나요
- 명령, 질의 영역에서 서로 다른 도메인 모델 쓰고 싶을 때
- 성능, 보안 문제로 데이터 변경과 읽기를 분리하고 싶을 때

- 명령, 질의 영역에서 서로 다른 도메인 모델 쓰고 싶을 때
	- 온라인 쇼핑몰
	- 재고 관리는 관계형 데이터베이스
	- 그러나 매번 상품 조회할 때는 여러 데이터를 묶어서 JSON 변환하면 시간이 많이 소요됨
	- 이 경우 CQRS로 JSON 형태로 도큐먼트 스토어에 저장해두면 좋음
	- 명령과 질의 모델이 강하게 결합되지 않으므로 서로 다른 팀에서 개발 가능
		- 독자적으로 각 모델을 발전

- 작업 분산과 데이터 경합 감소
	- 보안 검증, 메시지 변환 등 높은 성능을 요구하는 데이터 쓰기 작업, 복잡한 조인 연산이나 데이터 매핑과 같은 질의 작업을 처리하는 경우 CQRS를 쓸 수 있음
	- 명령과 질의를 분리해 서로가 미치는 성능 영향도 줄이고, 시스템 확장성도 올릴 수 있다.
	- 질의만 더 확장하고, 변경은 줄이는 등 서로 다른 확장성 요구사항도 처리 가능

#### 고려해야 할 사항들
- 명령, 질의 분리해 높은 가용성 제공
- 질의는 거의 무한한 확장 가능
- 단, 명령은 데이터 샤딩 등을 사용해야 할 수 있고, 이때 데이터를 나누고 합치는 과정에서 발생할 수 있는 잠재적인 데이터 충돌을 방지해야 한다.

- CQRS는 높은 일관성이 필요한 경우 쓰면 안된다.
- 데이터는 비동기로 동기화된다.
- 동기 복제를 하면 데이터 스토어 잠금을 얻기 위해 서로 경합하고, 그 결과 지연 시간이 증가한다.

- 명령과 질의를 분리하기 위해 ORM을 쓸 수 없다.
- 이런 도구는 DB로 조합 모델을 만드므로 CQRS를 할 때는 생성된 모델을 직접 수정하거나 처음부터 만들어야 한다.

- CQRS는 대단해보이지만 이를 적용하면 시스템 구조가 매우 복잡해진다.
- 이벤트 소싱 패턴으로 데이터 소스 변경을 관리해야 하고, 중복 및 실패 이벤트 처리가 필요하다.
- 따라서 명령 및 질의가 간단하고, 비즈니스 로직이 복잡하지 않다면 CQRS는 쓰지 않는 게 좋다.
- 오히려 관리의 복잡도 증가로 인한 단점이 더 크다.

#### 관련 패턴들
- 이벤트 소싱 패턴
	- 명령 서비스에서 갱신 이벤트를 질의 서비스로 이벤트 소싱으로 전달
	- 약한 일관성을 제공, 시스템 구조를 더 복잡하게 만든다
- 구체화된 뷰 패턴
	- 명령과 질의 모델이 간단하면 CQRS 대신 구체화된 뷰 패턴 사용해서 확장성 높이는 게 좋다
- 데이터 샤딩 패턴
	- 데이터를 분리하고 명령 서비스를 확장
	- 질의 서비스는 복제가 쉬워서 이점이 크지 않다
- API 보안

### 4.6.3 데이터 확장 패턴 정리

|패턴|사용하면 좋은 경우|사용해서는 안 되는 경우|이점|
|---|---|---|---|
|**데이터 샤딩**|• 데이터에 각 데이터를 고유하게 식별할 수 있는 하나 또는 그 이상의 필드가 있어서 데이터를 하위 집합으로 묶을 수 있는 경우|• 샤드 키를 통해 각 샤드에 균등한 크기의 데이터를 저장할 수 없는 경우<br>• 전체 데이터 셋의 중앙 값 실행과 같이 데이터 처리 작업에 전체 데이터가 필요한 경우|• 각 데이터의 필드를 조합해서 샤드 키를 만들고 데이터를 샤드 단위로 묶을 수 있음<br>• 클라이언트와 지역적으로 가까운 곳에 관련 데이터를 저장하고 최적화할 수 있음<br>• 계층적 샤드 또는 시계열 기반 샤드를 만들어서 검색 시간을 최적화할 수 있음<br>• 샤드 키가 없는 질의를 별 생각없이 사용해서 처리할 수 있음|
|**명령 및 조회 책임 분리(CQRS)**|• 애플리케이션에서 다음과 같이 고성능을 요구하는 데이터 변경 작업을 처리하는 경우:<br>- 데이터 검증<br>- 보안성 검증<br>- 메시지 변환<br>• 복잡한 조인 연산 또는 데이터 매핑과 같이 고성능 질의 연산을 처리해야 하는 경우|• 명령(데이터 변경)과 조회(데이터 질의) 서비스 간 높은 일관성이 요구되는 경우<br>• 명령과 질의 모델 간 연관성이 큰 경우|• 명령 및 질의 작업 간 영향도를 최소화 함<br>• 명령 및 질의 데이터를 각각의 경우에 잘 맞는 별도의 데이터 스토어에 저장하고 사용할 수 있음<br>• 명령 및 질의 간에 별도의 보안 정책을 적용할 수 있음<br>• 명령 및 질의 서비스를 서로 다른 팀에서 개발하고 관리할 수 있음<br>• 고가용성을 제공함|

## 4.7 성능 최적화 패턴
- 데이터는 병목 현상의 주요 원인 중 하나
- 확장하기 어렵고 일관성 등의 요구사항으로 경합이 벌어지며, 분산된 데이터 동기화에 대한 부하가 발생

- 성능을 올리는 기본적인 방법 중 하나는 색인 만들기
	- 검색 성능을 올릴 수 있지만 과도한 색인은 오히려 읽기와 쓰기 성능 모두 저하
	- 쓰기는 여러 개의 색인을 변경해야 해서 쓰기가 증가하고
	- 읽기는 모든 색인을 메모리에 가지고 있을 수 없기에 여러 번의 읽기 작업이 오히려 수반될 수도 있다.

- 읽기 모델을 간단하게 만드는 데는 데이터 비정규화가 좋다
- 조인 연산을 제거해 읽기 성능을 비약적으로 향상
- 쓰기 작업에는 정규화된 데이터 스토어를, 읽기 작업에는 비정규화된 데이터 스토어를 쓰면 좋다.

- 혹은 데이터를 처리하는 곳 가까이 두거나, 처리 코드를 데이터와 가까운 곳에서 실행하거나, 전송하는 데이터 양을 줄이거나, 미리 데이터를 전처리하거나 등 여러 방법이 있다.

### 4.7.1 구체화된 뷰 패턴
- materialized view pattern은 데이터를 처리하는 곳 가까운 곳에 미리 구체화된 뷰로 저장해 질의에 대한 데이터 조회를 효과적으로 처리
- 모든 데이터를 로컬 데이터 스토어에 저장, 데이터 포맷을 질의로 처리하는 데 최적화된 형태로 바꾼다.
- 이를 통해 더 이상 필요한 데이터를 가져오기 위한 서비스를 그때그때 호출할 필요가 없다.

#### 어떻게 동작할까요
![](files/Pasted%20image%2020251001211633.png)
- 의존 서비스에서 데이터를 가져와서 로컬 데이터 스토어에 저장하고, 구체화된 뷰를 만든다
- 조합 데이터 서비스 패턴처럼 질의를 효과적으로 처리할 수 있는 최적화된 뷰를 만들기도 한다.

- 이 패턴에서는 의존 서비스로부터 데이터를 비동기로 복제해서 사용
- 사용하는 DB가 비동기 복제를 지원하면 이걸 써서 가져오기도 함
- 없으면 이벤트 소싱 패턴으로 데이터를 복제

#### 어떻게 사용할 수 있나요
- 복잡한 조인 연산을 제거하고, 관련 서비스에 대한 결합도를 낮추어서 읽기 관련 작업을 효과적으로 처리

- 데이터 읽기 효율성 증대
	- 데이터 일부를 로컬에서 처리할 수 있고 나머지는 지연시간이 긴 외부 데이터 소스에서 가져와도 관계없을 때 사용
	- 리뷰 전체를 가져오지 말고 최고 리뷰, 최악 리뷰를 미리 복사해서 상품 세부 정보를 미리 제공하는 등
	- 같은 DB여도 조인은 오래 걸릴 수 있다.
	- 미리 질의 처리에 알맞는 데이터를 구체화된 뷰로 변환해두면 데이터를 더 효율적으로 처리하고 제공할 수 있다.
- 안전한 시스템에서 민감하지 않은 데이터 제공
	- 민감하지 않은 데이터만 미리 복제해주면 보안 및 검증 없이 빠르게 제공할 수 있다.

#### 고려해야 할 사항들
- 의존하는 데이터가 다른 유형의 데이터 스토어에 있거나, 불필요한 데이터가 많이 있는 경우 하위 데이터만 복제하고, 적절한 포맷으로 변경해서 저장해야 한다.
- 데이터를 로컬에서 처리함으로써 전반적으로 질의 성능을 올리고, 전송하는 데이터 양을 줄여서 대역폭 소모를 줄일 수 있다.
- 데이터 잠금 경합이 발생하지 않도록 비동기 복제를 사용한다.

- 읽기 성능 올려주고, 불필요한 데이터 처리할 필요 없고, 의존하는 서비스 파악할 필요 없어서 서비스 로직이 간단해짐

- 서비스 탄력성을 제공함
- 데이터가 로컬 스토어에 복제되어 원천 데이터 제공하는 곳에 문제가 생겨도 문제가 없음

- 그러나 데이터를 의존 서비스로부터 아주 빠르게 가져올 수 있거나, 의존하는 서비스가 빠르게 바뀌는 경우, 일관성이 매우 중요한 경우 쓰면 안 된다.
- 저장한 데이터가 무용해지고, 오히려 데이터 불일치를 초래

- 데이터 양이 아주 크거나, 원천 데이터가 자주 바뀌면 역시 이 패턴을 쓰면 안 된다
- 복제 지연이 발생할 수 있고, 대역폭 소모도 많아 전반적인 성능 및 정확도에 영향을 미친다.
- 이 경우 데이터 지역성 패턴을 쓰는 게 좋다.

#### 관련 패턴들
- 데이터 지역성 패턴
	- 코드 실행을 데이터와 가까운 곳에서 해서 데이터 조회를 더 효율적으로
- 조합 데이터 서비스 패턴
	- 데이터 조합을 서비스 수준에서 할 수 있거나, 의존 서비스가 정적 데이터를 가지고 있어서 캐싱할 수 있는 경우 구체화된 뷰 패턴 대신 사용 가능
- 명령 및 질의 책임 분리 패턴
	- 구체화된 뷰 패턴에서 질의 처리를 위해서 CQRS 사용 가능
- 이벤트 소싱 패턴
	- 데이터를 다른 곳으로 복제할 때 사용

### 4.7.2 데이터 지역성 패턴
- data locality pattern
	- 데이터 처리 로직을 최대한 데이터와 가까운 곳에서 실행하는 것
	- 서비스를 데이터와 같은 위치에 배포하거나, 데이터 스토어에서 로직을 실행하는 것
	- 실행 코드가 거의 제한 없이 데이터에 접근할 수 있어 빠른 실행이 가능하고, 결과 데이터를 보낼 때 소비하는 대역폭을 줄일 수 있다.

#### 어떻게 동작할까요
![](files/Pasted%20image%2020251001212157.png)
- 데이터를 옮기는 것보다 실행 코드를 옮기는 게 성능을 더 향상할 수 있다.
- CPU 자원이 충분하면 데이터 노드에서 질의를 처리해서 네트워크 전송 없이 대부분 데이터를 로컬에서 처리

- 이게 불가능하다면 같은 리전이나 데이터 센터에 배치해서 대역폭 소비를 최소화

![](files/Pasted%20image%2020251001213714.png)

- 혹은 store procedure로 만들어서 실행

#### 어떻게 사용할 수 있나요
- 데이터 읽기 지연 시간 감소
	- 하나 이상의 데이터 스토어로부터 데이터를 읽어와서 정렬, 조인할 때 쓰면 좋다
	- 데이터 스토어에서 서비스를 실행하거나, 가장 많은 데이터를 전송해야 하는 데이터 스토어에서 서비스를 실행하면 네트워크 전송 양을 줄일 수 있다.
	- 또는 조합 서비스 패턴에서 서비스가 데이터 스토어와 다른 서비스 데이터를 조인하는 경우, 조합 서비스를 데이터 스토어 노드나 가까운 노드에서 실행하면 전반적인 성능을 향상할 수 있다.
- 데이터 조회 시 네트워크 대역폭 소비 감소
	- 데이터 집계나 필터링을 위해 여러 데이터 소스를 봐야하는 경우 유용하다
	- 이런 질의 결과는 일반적으로 입력 데이터에 비해 매우 작기 때문
	- 네트워크 대역폭 소비를 최적화할 수 있음
	- 혹은 데이터 스토어가 아주 크고 클라이언트가 지리적으로 분산된 경우 쓰기 좋다
	- 전반적으로 네트워크 대역폭에서 병목 현상을 겪는 경우 적용하기에도 좋다


#### 고려해야 할 사항들
- 데이터 노드의 CPU 자원 사용을 최대화할 수 있다
- 대부분 데이터 노드는 I/O 작업에 치중 -> CPU가 노는 경우가 많다
- 그렇다고 모든 실행 코드를 데이터 노드에서 실행할 수는 없다. 지나치게 많은 부하가 갈 수 있음

- 입력과 결과 데이터 크기가 큰 차이가 없는 경우 안 쓰는 게 좋다
- 성능 향상이나 대역폭 소비 절감 효과는 하나도 없이 노드 부하만 가중시킨다
- 네트워크 대역폭 소비 감소와 CPU 사용률 최대화 간 이점을 잘 조율해야 한다
- 데이터 노드에서 코드를 실행해서 발생할 수 있는 문제점보다 데이터 크기를 줄임으로써 얻을 수 있는 이점이 클 때 사용

- 데이터 스토어가 질의 마이크로서비스에서 전용으로 사용하는 경우에만 실행 코드를 데이터 스토어로 옮겨야 함
- 공유 데이터베이스에서 store procedure를 실행하면 성능 및 관리 문제를 일으킬 수 있으므로 피해야 함
- 운영하다가 실수로 데이터 스토어 장애가 발생할 수도 있음
- 성능 이점이 없다면 서비스에서 직접 코드를 실행하는 게 더 좋다

#### 관련 패턴들
- 구체화된 뷰 패턴
	- 실행 코드 가까운 곳에 데이터 배치
	- 데이터 크기가 작거나 읽기 과정에서 복잡한 조인, 데이터 변환 등으로 CPU 많이 소모하는 경우
- 캐싱 패턴
	- 전처리한 데이터를 저장하고, 반복된 질의에 해당 데이터를 제공해 성능 향상

### 4.7.3 캐싱 패턴
- 이전에 처리한, 조회한 데이터를 메모리에 저장하고 향후 유사한 질의에 대하여 저장한 데이터를 사용하는 방식
- 서비스에서 반복하는 데이터 처리를 줄여주고, 이미 저장된 데이터와 연관된 의존 서비스를 호출하지 않아도 됨
#### 어떻게 동작할까요
- 캐시는 일반적으로 메모리에 데이터를 저장하는 데이터 스토어 형태로, 이전 데이터를 미리 저장해두고 이를 재사용
- 있으면 캐시 히트, 없으면 캐시 미스

- 캐시 미스가 발생하면 시스템은 데이터를 처리하거나 가져오고, 다시 캐시에 저장
- 이를 read-through cache operation이라고 한다.

- 데이터 변경 요청을 처리하는 경우 데이터 스토어에 이를 반영하고, 캐시에 저장된 데이터를 삭제하는데 이를 write-through cache operation이라고 한다.
- 캐시 데이터가 틀린 경우 cache invalidation이 반드시 필요하다.
- 이렇게 데이터를 읽고 변경하는 방식을 cache aside 방식이라고 한다.
- 대부분의 상업용 캐시가 이를 지원

- 캐시는 클라, 서버 둘 다 존재 가능
- 로컬 캐시를 쓰거나 공유 캐시를 쓰거나

- 메모리를 다 쓴 경우 이전 데이터를 지워야 함.
- 가장 자주 사용하는 정책은 LRU(Least Recently Used)
- 가장 오랫동안 사용되지 않은 데이터를 삭제하고, 그 자리에 새로운 데이터를 저장
- 가장 예전에 저장한 데이터를 지우는 FIFO, 가장 최근에 사용한 데이터를 지우는 MRU 등
- 혹은 발생한 이벤트 값에 따라서 데이터를 지우는 등
- 애플리케이션 성격에 맞게 고려

- 데이터를 캐시에 저장했는데, 다른 곳에서 원본 데이터를 변경할 수도 있다
- 캐시에 어떤 데이터를 오랫동안 가지고 있으면 캐시와 실제 데이터 사이의 불일치가 생길 수 있다
- 이는 캐시 데이터별로 유효 시간을 정함으로써 해결 가능

#### 어떻게 사용할 수 있나요
- 데이터 조회 시간 단축
	- 데이터 스토어보다 캐시가 더 빠른 경우 캐시를 쓸 수 있다.
	- 특히 데이터 스토어에서 데이터를 가져오는데 연산이 복잡하거나, 원격지에 있어서 네트워크 지연 시간이 높은 경우 사용 가능
- 정적 콘텐츠를 가져오는 시간 단축
	- 정적 데이터 혹은 거의 변경되지 않는 데이터 제공할 때 좋다
	- 메모리에 저장할 수 있는 정적 데이터는 해당 데이터 전체를 메모리에 저장하고, TTL 없이 제공해도 좋다.
	- 이를 통해 정적 데이터를 가져오는 시간을 획기적으로 개선할 수 있고, 원천 데이터 스토어에서 데이터를 읽어올 필요를 없게 만든다.
- 데이터 스토어 경합 감소
	- 데이터 스토어에 읽기 요청을 적게 보내서 데이터 스토어에서 발생할 수 있는 경합을 줄일 수 있다.
	- 데이터 불일치에 크게 영향받지 않는 경우 쓰기 작업을 많이 처리하는 스토어에 이 패턴을 적용해서 읽기 부하를 줄이고, 시스템 안정성을 올릴 수 있다.
	- 이 방법은 언젠가는 TTL이 지나거나 write-through cache 동작으로 데이터가 일치된다.
- 데이터 조회 시간 단축을 위해 데이터를 미리 가져오기
	- 주로 사용하는 질의 내용이 무엇인지 알고 있다면, 데이터 전체 혹은 일부를 미리 가져와서 캐시에 저장할 수 있다.
	- 보통 최근 일주일 내 주문 데이터를 요청한다면 서비스를 시작할 때 최근 일주일 분량의 데이터를 미리 가져와서 캐시에 저장할 수 있다.
	- 캐시가 없으면 초기 요청을 처리하는 과정에서 캐시 미스로 인해 서비스와 데이터 스토어에 많은 부하가 발생할 수도 있다.
	- 혹은 그 다음 질의에서 어떤 데이터가 필요한지 미리 예측해서 데이터를 미리 가져오는 것도 가능하다.
- 데이터 스토어 의존성 해소를 통한 고가용성 구현
	- 서비스 가용성이 데이터 일관성보다 더 중요한 경우, 캐싱을 통해 고가용성을 구현하는 것도 가능하다.
	- 백엔드 데이터 스토어가 제대로 동작하지 않는 경우에도 서비스는 캐시 데이터로 계속 동작할 수 있다.
	- 캐싱 패턴을 통해 로컬 캐시에 데이터가 없는 경우 공유 혹은 분산 캐시에서 데이터를 가져오고, 이마저도 없으면 데이터 스토어에서 데이터를 가져오는 구조
	- 이 패턴은 circuit breaker와 함께 사용해서 몇 차례 실패 후 백엔드 서비스나 데이터 스토어가 정상이 되었을 때 다시 연결을 복구하도록 만들 수도 있다.
	- 공유 캐시를 사용하는 경우 부 캐시 인스턴스를 항시 대기 상태로 두고, 데이터를 복제해두면 주 캐시 인스턴스가 동작하지 않는 경우 부 캐시를 쓰도록 해 가용성을 높이는 것도 가능하다.
![](files/Pasted%20image%2020251002195429.png)
- 단일 노드에서 저장할 수 없는 데이터를 캐시에 저장하기 
	- 로컬 캐시나 공유 캐시가 필요한 모든 데이터를 저장할 수 없는 경우 분산 캐싱 시스템을 쓸 수도 있다
	- 데이터를 나누고 복제함으로써 확장성과 탄력성을 제공
	- read through, write through 동작을 지원하고, 데이터 스토어로부터 바로 데이터를 가져오고 변경하는 것도 가능
	- 분산 캐싱 시스템은 필요한만큼 캐시 서버를 추가해 확장성을 간단하게 구현할 수 있다.
	- 물론 분산 캐시는 로컬 캐시만큼 빠르지 않으며, 시스템 복잡도가 증가한다.
	- 분산 캐시를 구성하는 모든 노드는 같은 네트워크 내에 존재해야 하며, 서로 통신할 때 상대적으로 많은 대역폭을 사용할 수 있어야 한다. 아니면 데이터 동기화 문제가 발생한다.
	- 클라이언트가 지리적으로 분산된 경우 분산 캐시로 가까운 곳에서 빠르게 데이터를 저장하고 응답할 수도 있다.

#### 고려해야 할 사항들
- 캐시 데이터를 단일 데이터 소스로 사용해서는 안 되며, 고가용성을 반드시 만족할 필요도 없다
- 캐시를 사용할 수 없어도 애플리케이션은 제대로 동작해야 한다.
- 캐시는 메모리에 데이터를 저장하므로 언제든지 사라질 수 있고, 장기적으로 데이터를 영구 저장하는 것은 반드시 데이터 스토어야한다.

- 응답 데이터 대부분이 정적이고, 일부분이 동적이면 정적인 데이터만 캐시에 저장하는 것도 방법이다.

- 캐시를 삭제하는 정책 대신 데이터가 흘러 넘칠 때 로컬 캐시가 이를 대응하도록 만들 수도 있다.
- 넘치는 데이터를 디스크에 저장한다.
- 단, 데이터 관리가 복잡해지므로 이는 원천 데이터를 가져오는 것보다 디스크가 빠를 때만 써야 한다.

- 캐시 유효 시간은 너무 길거나 짧지 않게, 적당한 시간을 지정한다.
- 캐시 유효 시간이 너무 길면 데이터 스토어와 캐시 데이터 간 불일치가 많아지고, 너무 짧으면 캐시를 쓰는 의미가 없어진다.
- 일관성보다 조회 비용이 중요하면 일부러 TTL을 길게 잡을 수도 있다.

- 로컬 캐시의 가장 큰 문제는 서비스를 확장할 때 각자 로컬 캐시를 관리하므로 캐시 간 데이터 불일치가 발생할 수도 있다.
- 이런 문제는 메시징 시스템을 통해 pub-sub 패턴이나 이벤트 소싱 패턴으로 캐시 무효화를 시킬 수도 있다.

![](files/Pasted%20image%2020251002200249.png)

- 불필요한 캐시를 추가하면 메모리 소비가 증가하고, 성능이 떨어지며 데이터 불일치가 발생할 수 있다
- 캐시 도입 전에 충분한 부하 테스트를 통해 성능은 물론 캐시 히트, CPU, 메모리 사용량 등을 파악해야 한다.

- 가능하면 데이터 스토어처럼 캐시도 배치 업데이트를 하는 게 좋다
- 높은 부하가 걸리는 상황에서 대역폭 사용과 성능을 최적화할 수 있다.
- 여러 캐시 데이터가 동시에 변경되는 경우 낙관적 또는 비관적 방식을 사용할 수 있다.
- 낙관적 방식은 여러 캐시에서 동시에 데이터를 변경하는 경우가 없다고 가정하고, 캐시 업데이트하기 전에만 캐시에 동시에 쓴 경우가 있는지 검사
- 비관적 방식은 전체 업데이트 시간 동안 잠금을 걸어 동시에 다른 곳에서 데이터를 변경하지 못하도록 한다.
	- 이는 확장성이 떨어지므로 아주 짧은 시간이 소요되는 경우에만 써야한다.

- 또한 캐시를 강제 만료하거나 데이터를 다시 만들 수 있게 하는 게 좋다.
- 그러면 클라에서 서비스가 캐시를 강제 갱신하도록 할 수 있다.
- 캐시를 저장할 때 캐시 키에 임의의 값을 조합하는 방식으로 이를 구현할 수도 있다.
	- 클라가 캐시 키를 그대로 쓰거나, 새롭게 바꾸거나
- 이는 브라우저 캐시에 많이 사용
- 클라가 임의의 URI 값을 바꿈으로써 브라우저 캐시를 초기화

- 몇몇 상용 캐시 서비스는 볼트 키 패턴을 통해 데이터 보안성 제공
- 하지만 대부분은 보안을 염두하고 설계되지 않았으므로 캐시 데이터를 외부에 제공하는 것은 피한다.
- 대신, 데이터 서비스 패턴으로 서비스에 캐시를 구현하고 API로 이를 제공하는 게 좋다.

![](files/Pasted%20image%2020251002200626.png)

#### 관련 패턴들
- 데이터 샤딩 패턴
	- 데이터 스토어 확장처럼 캐시도 확장 가능
	- 지리적으로 데이터를 분산해서 데이터와 실 사용처를 가깝게 만들 수도 있다.
- 탄력적 연결성 패턴
	- 캐시 데이터를 사용할 수 없는 경우 데이터 원천을 통해 서비스
- 데이터 서비스 패턴
	- API 보안성과 데이터 서비스를 함께 사용해 분산 캐시에 대한 서비스 계층을 제공하고, 데이터 사용자에게 좀 더 비즈니스 친화적인 API 제공
- 볼트 키 패턴
	- 액세스 토큰을 통해 서드파티가 캐시에 안전하게 접근할 수 있게 해줌
	- 이는 캐싱 시스템이 이 기능을 지원할 때 써야함
- 이벤트 소싱 패턴
	- 모든 로컬 캐시에 캐시 무효화 요청을 전파할 때 쓸 수 있음
	- 캐시 데이터에 대한 약한 일관성 제공, 데이터 소스가 여러 서비스로 인해 변경되어 데이터가 쓸모없어지는 경우를 최소화해줌

### 4.7.4 정적 콘텐츠 호스팅 

#### 어떻게 동작할까요

#### 어떻게 사용할 수 있나요

#### 고려해야 할 사항들

#### 관련 패턴들


### 4.7.5 성능 최적화 패턴 정리


|패턴|사용하면 좋은 경우|사용해서는 안 되는 경우|이점|
|---|---|---|---|
|**구체화된 뷰**|• 데이터 일부를 로컬에서 제공할 수 있으며 나머지 데이터는 지연 시간이 높은 외부 데이터 스토어에서 가져와서 처리할 수 있을 때<br>• 로컬 스토어로 옮기는 데이터 크기가 작으며 거의 변경되지 않을 때<br>• 보안 시스템을 통해서만 접근할 수 있지만 민감하지 않은 데이터를 제공해야 할 때|• 데이터를 외주 서비스에서 낮은 지연 속도로 가져올 수 있을 때<br>• 외주 서비스의 데이터가 빠르게 변경될 때<br>• 데이터의 일관성이 더 중요할 때|• 애플리케이션에 적합한 다양한 데이터베이스나 데이터를 저장할 수 있음|
|**데이터 지역성**|• 데이터를 여러 데이터 스토어에서 읽어서 조인이나 데이터 애그리게이션 연산을 수행할 때<br>• 데이터 스토어가 매우 크고 클라이언트가 지리적으로 분산되어 있을 때|• 질의의 결과가 입력 데이터 대부분을 포함할 때<br>• 데이터 노드에서 데이터를 처리하는 비용이 데이터를 네트워크로 전송하는 비용보다 클 때|• 데이터 조회 지연 시간을 낮추고 네트워크 대역폭 소모를 줄임<br>• CPU 사용 효율을 증대하고 전반적인 성능을 최적화함<br>• 결과 데이터를 캐시에 저장하고 요청을 더 효과적으로 처리함|
|**캐시**|• 정적 데이터 또는 거의 변경되지 않은 데이터 차원에 적합함<br>• 애플리케이션이 하나 이상의 클라이언트로부터 동일한 질의를 여러 번 받는 경우, 특히 다음 질의가 어떤 데이터를 요구할지 예측할 수 있는 경우<br>• 데이터 스토어 간 경합이 심하거나 여러 클라이언트로부터 동시에 데이터 조회 요청이 발생하는 것을 제대로 처리할 수 없을 때|• 데이터가 자주 변경되는 경우<br>• 신뢰할 수 있는 데이터 원본으로 사용해서는 안됨<br>• 데이터가 아주 중요하여 시스템이 데이터 불일치를 처리할 수 없는 경우|• 데이터 일부를 캐시에 저장해서 성능을 향상시킬 수 있음<br>• 캐시 배치 기법을 통해 중복 연산을 제거하고 성능을 향상시킴<br>• 캐시에 정적 데이터를 미리 읽어와서 제공할 수 있음<br>• 캐시 삭제 정책과 함께 사용하면 최근 또는 요구되는 데이터를 캐시에 저장할 수 있음|
|**정적 콘텐츠 호스팅**|• 클라이언트에서 요구하는 데이터 일부 또는 전체가 정적 콘텐츠인 경우<br>• 정적 데이터를 여러 환경 또는 지리적으로 떨어진 여러 위치에 제공해야 하는 경우|• 접근 시간이나 위치를 기반하는 것과 같이 클라이언트에 제공하기 전 정적 콘텐츠를 수정해야 하는 경우<br>• 제공하는 정적 콘텐츠의 크기가 작은 경우<br>• 클라이언트 측에서 정적 데이터와 동적 데이터를 받아서 조합할 수 없는 경우|• 지리적으로 데이터를 나누고 클라이언트와 가까운 곳에 저장함으로써 클라이언트에게 더 빠르게, 낮은 지연 시간으로 콘텐츠를 제공할 수 있음<br>• 렌더링 서비스의 자원 소모량을 줄일 수 있음|

## 4.8 신뢰성 패턴

### 4.8.1 트랜잭션 패턴

#### 어떻게 동작할까요

#### 어떻게 사용할 수 있나요

#### 고려해야 할 사항들

#### 관련 패턴들


### 4.8.2 신뢰성 패턴 정리

|패턴|사용하면 좋은 경우|사용해서는 안 되는 경우|이점|
|---|---|---|---|
|**트랜잭션**|• 작업이 여러 단계나 작업으로 구성되어 있으며 모든 단계가 성공해야 해당 작업이 올바르게 끝났다고 볼 수 있는 경우|• 작업이 한 단계로 이루어진 경우<br>• 애플리케이션 작업이 여러 단계로 이루어져 있지만 몇몇 단계가 실패해도 문제가 되지 않는 경우|• ACID 속성을 따름<br>• 여러 독립적인 트랜잭션을 처리할 수 있음|

## 4.9 보안: 볼트 키 패턴

### 4.9.1 볼트 키 패턴 정리

|패턴|사용하면 좋은 경우|사용해서는 안 되는 경우|이점|
|---|---|---|---|
|**볼트 키**|• 최소한의 지연 시간으로 데이터에 안전하게 접근하고자 할 때<br>• 데이터 스토어가 서비스 호출에 대한 인증 및 권한 검사를 할 수 있을 만큼 충분한 연산 능력을 가지지 못하는 경우|• 세밀한 데이터 보호가 필요한 경우<br>• 질의가 데이터 스토어에서 실행되며 고성능성을 요구하는 경우<br>• 외부에 노출한 데이터 스토어가 키에 기반한 접근 검증을 할 수 있는 경우|• 볼트 키를 통해 데이터 스토어에 안전하게 직접 접근할 수 있음<br>• 데이터 접근 검증을 위해 중앙 ID 확인 서비스를 호출하는 것보다 적은 비용으로 검증할 수 있음|

## 4.10 데이터 관리 패턴 구현 기술


### 4.10.1 관계형 데이터베이스 관리 시스템


### 4.10.2 아파치 카산드라

### 4.10.3 아파치 HBase


### 4.10.4 몽고DB


### 4.10.5 레디스

### 4.10.6 아마존 dynamoDB

### 4.10.7 아파치 HDFS


### 4.10.8 아마존 S3

### 4.10.9 애저 코스모스DB


### 4.10.10 구글 클라우드 스패너

### 4.10.11 구현 기술 정리

## 4.11 테스팅


## 4.12 보안

## 4.13 관측 가능성 및 모니터링


## 4.14 데브옵스


## 4.15 데브옵스 



